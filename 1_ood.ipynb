{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFWnwGiwu-EP"
      },
      "source": [
        "# **Trustworthy Machine Learning**\n",
        "### Winter Semester 2022-2023\n",
        "### Lecturer: Seong Joon Oh\n",
        "### Tutor: Alexander Rubinstein\n",
        "### **Exercise 1 -- OOD Generalisation**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Group number**: >>> PLEASE FILL IN <<<\n",
        "\n",
        "**Student names**: >>> PLEASE FILL IN <<<\n",
        "\n",
        "**Student emails**: >>> PLEASE FILL IN <<<\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "DWwbAYCTmVZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#### **Submission deadline: 21/11/2022 at 23:59.**\n",
        "\n",
        "In the first exercise, you will answer questions on the out-of-distribution (OOD) generalisation problems in machine learning.\n",
        "\n",
        "#### **Policy for the first exercise**\n",
        "This exercise is a **group exercise**. The same grade will be conferred to each member of the group based on the submission. Please report cases where any team member contributes significantly less than the other members of the same group. From the first exercise, the exercise grade will **count towards the final grade**.\n",
        "\n",
        "####**Submission**\n",
        "Follow the below four steps.\n",
        "\n",
        "(1) Copy this colab file to your local gdrive;\n",
        "\n",
        "`File > Save a copy in Drive`\n",
        "\n",
        "(2) Work on the solution on your local copy;\n",
        "\n",
        "(3) Pin the version for submission in history;\n",
        "\n",
        "`Click on \"All changes saved\" or \"Last saved at XX:XX AM/PM\" next to the drop-down menus at the top > Select version to submit > Click on three vertical dots (vertical ellipsis) > Rename > Write \"Submission\" `\n",
        "\n",
        "(4) Share your local colab with `stai.there@gmail.com` before the deadline.\n",
        "\n",
        "`Click on \"Share\" at the top-right corner > Put stai.there@gmail.com in \"Add people and groups\" > Give the \"Viewer\" right and tick on \"Notify people\" > Click send.`\n",
        "\n",
        "Note that we are able to see the edit history with time stamps, so please ensure that you stop working on your notebook before the deadline."
      ],
      "metadata": {
        "id": "lZy4hH2ZmlOc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmGAkVwBwCDu"
      },
      "source": [
        "## **Out of distribution generalization**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Settings and real-world scenarios (5 points)\n",
        "\n",
        "It is important to propose a plausible setting for studying ML methods. To make an argument that the proposed setting is indeed plausible, one would come up with an example real-world scenario. Let's try this.\n",
        "\n",
        "**Description of the setting.**\n",
        "\n",
        "- Development resources\n",
        "  - Multiple image datasets $D_1$, $D_2$, $D_3$, …, $D_n$ with the same task (image classification with the possible set of class labels $Y$). Each dataset consists of IID samples from distributions $P_1$, $P_2$, …, $P_n$. Assume $P_i\\neq P_j$ for all $i\\neq j$. \n",
        "  - Every image sample $x$ is labelled with the image class $y\\in Y$.\n",
        "  - For each image $x$, you know which dataset it belongs to.\n",
        "  - You have collected a few *unlabelled samples* $D_{n+1}$ from the deployment environment $P_{n+1}$.\n",
        "\n",
        "- Deployment environment\n",
        "  - The stream of inputs follow the distribution $P_{n+1}$. This distribution is different from those of the training datasets: $P_i \\neq P_{n+1}$ for all $i\\in\\{1,...,n\\}$.\n",
        "\n",
        "**Q1**: How is this setting different from the \"Domain Generalization\" setting defined in Lecture 2? **(2 points)**\n",
        "\n",
        "**Q2**: Can you present an example real-world scenario for this setting? **(3 points)**\n"
      ],
      "metadata": {
        "id": "yzsKsW7Zgd4F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Identifying the exact setting in research work (4 + 4 = 8 points)\n",
        "\n",
        "Read the paper \"[Learning from Failure: Training Debiased Classifier from Biased Classifier](https://proceedings.neurips.cc/paper/2020/file/eddc3427c5d77843c2253f1e799fe933-Paper.pdf)\" published at NeurIPS 2020. \n",
        "\n",
        "**Q1**: Identify an _exhaustive_ list of development resources used for training and selecting the model in the method `Learning from Failure`. This includes training/validation datasets and corresponding labels as well as any type of human guidance or wisdom. **(4 points)**\n",
        "\n",
        "**Q2**: As we have seen in the lecture, feature selection is an impossible problem when the needed cue for the task is unknown to the learner. How does the `Learning from Failure` method provide this necessary information on the needed cue to the learner? Which assumptions on the task-relevant cue are made and how are they exploited by the given method? **(4 points)**\n",
        "\n"
      ],
      "metadata": {
        "id": "hnAACneNijH8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87F-PunowUDY"
      },
      "source": [
        "## 1.3 Equivalence of losses (5 + 5 = 10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2P1vxUSwUDY"
      },
      "source": [
        "Again, the NeurIPS 2020 paper \"[Learning from Failure: Training Debiased Classifier from Biased Classifier](https://proceedings.neurips.cc/paper/2020/file/eddc3427c5d77843c2253f1e799fe933-Paper.pdf)\" defines the Generalized Cross Entropy (GCE) loss as follows:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\text{GCE}(p(x; \\theta), y, q) = \\dfrac{1 - p_y(x;\\theta)^q}{q}\n",
        "\\end{equation*}\n",
        "\n",
        "where $p(x)\\in[0,1]^{|Y|}$ is the prediction vector for input $x$ with probabilities $p_y$ for each class $y\\in Y$ and $q>0$ is a scalar.\n",
        "\n",
        "Given that the Cross Entropy (CE) loss is\n",
        "\n",
        "\\begin{equation*}\n",
        "\\text{CE}(p(x; \\theta), y) = -\\log p_y(x;\\theta)\n",
        "\\end{equation*}\n",
        "\n",
        "Prove the following:\n",
        "\n",
        "- (5 points): For all $p$ and $y$, $\\text{GCE}(p,y,q) \\rightarrow \\text{CE}(p,y)$ as $q\\downarrow 0$.\n",
        "- (5 points): For all $p$, $y$, and $q>0$,\n",
        " $$\\dfrac{\\partial\\, \\text{GCE}(p(x; \\theta), y, q)}{\\partial\\, \\theta} = p^q_y\\,\\dfrac{\\partial\\, \\text{CE}(p(x; \\theta), y)}{\\partial\\, \\theta}.$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tqUvqezwUDY"
      },
      "source": [
        "## 1.4 Intro to dSprites dataset (2 + 3 = 5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: for this and the following exercises we suggest using Google Colab environment with a GPU. If you exhausted your GPU-time limits you can register a new free Google account and continue working from it."
      ],
      "metadata": {
        "id": "FK3wK4GZ6EkP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETDBdxBLwUDZ"
      },
      "source": [
        "We will use [dSprites dataset](https://github.com/deepmind/dsprites-dataset) for all the experiments in this homework.\n",
        "It contains images with different cues: color, shape, scale, orientation, horizontal and vertical positions (posX and posY).\n",
        "  \n",
        "Numbers of different values for each cue are the following:\n",
        "\n",
        "- color: 3 (red, blue, green)\n",
        "- shape: 3 (square, ellipse, heart)\n",
        "- scale: 6 (from smallest to biggest)\n",
        "- orientation: 40 (different angles)\n",
        "- posX, posY: 32 (different coordinates)\n",
        "\n",
        "Throughout this homework we will label images according to this values by uniformly distributing them into \"NUM_CLASSES\" classes."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torchmetrics\n",
        "!pip install -q gdown"
      ],
      "metadata": {
        "id": "vQDnY5jy5mkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --branch main https://github.com/AlexanderRubinstein/UT-TML.git &> /dev/null"
      ],
      "metadata": {
        "id": "1t2qUYPvcLne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "in5M16FMi4qj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "from IPython.display import clear_output\n",
        "import gdown\n",
        "from typing import (\n",
        "    Dict,\n",
        "    List,\n",
        "    Tuple,\n",
        "    Callable,\n",
        "    Union,\n",
        "    Any\n",
        ")\n",
        "\n",
        "\n",
        "# local modules\n",
        "ROOT = \"/content\"\n",
        "REPO_NAME = \"UT-TML\"\n",
        "REPO_PATH = os.path.join(ROOT, REPO_NAME)\n",
        "SRC_PATH = os.path.join(REPO_PATH, \"src\") \n",
        "sys.path.insert(0, SRC_PATH)\n",
        "import utils  \n",
        "import models\n",
        "import datasets\n",
        "from datasets import (\n",
        "    DSPRITES_NPZ_PATH, \n",
        "    NUM_CLASSES,\n",
        "    GROUND_TRUTH_CUE,\n",
        "    EASY_TO_BIAS_CUE,\n",
        "    IS_DSPRITES_COLORED,\n",
        "    N_COLORS,\n",
        "    TEST_DATASET_SIZE, \n",
        "    TRAIN_DATASET_SIZE,\n",
        "    DEFAULT_DSPRITES_HOLDER_ARGS\n",
        ")\n",
        "import train\n",
        "import experiments\n",
        "sys.path = sys.path[1:]\n",
        "\n",
        "\n",
        "DSPRITES_NPZ_URL = (\n",
        "    \"https://github.com/deepmind/dsprites-dataset/raw/master/\"\n",
        "    \"dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz\"\n",
        ")\n",
        "ADVERSARIALLY_ATTACKED_CUE = \"shape\"\n",
        "\n",
        "DEFAULT_START_LR = 0.01\n",
        "\n",
        "\n",
        "OFF_DIAG_PROPORTION = 0.01\n",
        "INVERTED_OFF_DIAG_PROPORTION = (\n",
        "    int(1 / OFF_DIAG_PROPORTION) if OFF_DIAG_PROPORTION != 0 else 1\n",
        ")\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "\n",
        "# DANN params\n",
        "ALPHA = 10\n",
        "BETA = 0.75\n",
        "GAMMA = 10\n",
        "D_LAMBDA = 1\n",
        "\n",
        "\n",
        "# adversarial attack params\n",
        "FGSM_EPS = 0.1\n",
        "FGSM_ALPHA = 0.5 \n",
        "\n",
        "\n",
        "CACHE_PATH = \"/tmp/ood_cache\"\n",
        "\n",
        "\n",
        "HELPER_FILES_FOLDER_URL = (\n",
        "    \"https://drive.google.com/drive/folders/\"\n",
        "    \"1wDHu0gktM_39NNCB-ru7ewVg-9MVfq-z?usp=sharing\"\n",
        ")\n",
        "HELPER_FILES_PATH = \"./1_ood\"\n",
        "\n",
        "\n",
        "utils.apply_random_seed(RANDOM_SEED)\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO7wAwNgwUDb"
      },
      "source": [
        "Let's download dSprites dataset and helper files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7MJDdIVwUDb"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(DSPRITES_NPZ_PATH):\n",
        "    os.system(f\"wget {DSPRITES_NPZ_URL} -O {DSPRITES_NPZ_PATH}\")\n",
        "if not os.path.exists(HELPER_FILES_PATH):\n",
        "    gdown.download_folder(\n",
        "        HELPER_FILES_FOLDER_URL, \n",
        "        output=HELPER_FILES_PATH, \n",
        "        quiet=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33xJHdxNwUDb"
      },
      "source": [
        "Very often in this homework we will use functions that will have names like \"prepare_something_maker\". They will be used to create factories (functions that make objects) which will be named like \"make_something\". \n",
        "\n",
        "These factories will be used to create almost all objects for our experiemnts (dataloaders, criterions, models, metrics, optimizers, schedulers, etc). Created objects will be pickled and saved in \"CACHE_PATH\" to just read them from the disk next time we want to create them again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz6KWKiQwUDb"
      },
      "source": [
        "Let's create a dataloader (making a correspondnig factory by [datasets.prepare_default_dsprites_dataloaders_maker](https://github.com/AlexanderRubinstein/UT-TML/blob/e3a65b74526f5ef0a7197bdc8081cb0d046e0b85/src/datasets.py#L824-L963)) that gives multiple labels. Each label will correspond to each cue:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9kNq7jWwUDc"
      },
      "outputs": [],
      "source": [
        "test_multilabel_dataloaders \\\n",
        "    = datasets.prepare_default_dsprites_dataloaders_maker(\n",
        "        is_multilabel=True,\n",
        "        split=\"test\",\n",
        "        dataset_size=TEST_DATASET_SIZE\n",
        "    )(None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFH1o-X9wUDc"
      },
      "source": [
        "We can visualize first batch of this dataloader using [utils.show_dataloader_first_batch](https://github.com/AlexanderRubinstein/UT-TML/blob/e3a65b74526f5ef0a7197bdc8081cb0d046e0b85/src/utils.py#L439-L470):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cDunquIwUDc"
      },
      "outputs": [],
      "source": [
        "test_multilabel_dataloader = test_multilabel_dataloaders[\"all_cues\"]\n",
        "utils.show_dataloader_first_batch(\n",
        "    test_multilabel_dataloader, \n",
        "    test_multilabel_dataloader.cue_names\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0rfldDtwUDd"
      },
      "source": [
        "Let's create a model (using [models.prepare_resnet18_maker](https://github.com/AlexanderRubinstein/UT-TML/blob/e3a65b74526f5ef0a7197bdc8081cb0d046e0b85/src/models.py#L98-L111)) and evaluate it (using [train.eval_model_on_test](https://github.com/AlexanderRubinstein/UT-TML/blob/e3a65b74526f5ef0a7197bdc8081cb0d046e0b85/src/train.py#L406-L448)) by computing accuracy (created by [train.make_accuracy](https://github.com/AlexanderRubinstein/UT-TML/blob/e3a65b74526f5ef0a7197bdc8081cb0d046e0b85/src/train.py#L451-L452)) on the above dataloader without any training (it should give random predictions). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYT9s6D4wUDd"
      },
      "outputs": [],
      "source": [
        "random_model = models.prepare_resnet18_maker(\n",
        "    pretrained=False, \n",
        "    n_channels=N_COLORS, \n",
        "    n_classes=NUM_CLASSES\n",
        ")()\n",
        "\n",
        "train.eval_model_on_test(\n",
        "    random_model, \n",
        "    test_multilabel_dataloaders, \n",
        "    make_metric=train.make_accuracy\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx-RfsxpwUDd"
      },
      "source": [
        "Let's load from disk and evaluate some pre-made models on this dataloader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWVsOqCLwUDd"
      },
      "outputs": [],
      "source": [
        "# load pre-made models \n",
        "model_A_path = os.path.join(HELPER_FILES_PATH, \"model_A\")\n",
        "model_B_path = os.path.join(HELPER_FILES_PATH, \"model_B\")\n",
        "\n",
        "if IS_DSPRITES_COLORED:\n",
        "    model_A_path += \"_colored\"\n",
        "    model_B_path += \"_colored\"\n",
        "\n",
        "model_A = utils.default_load_func(model_A_path)\n",
        "model_B = utils.default_load_func(model_B_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate model_A and model_B as in the example above and tell which cues they are trained to predict (2 points)."
      ],
      "metadata": {
        "id": "C3E_0vMYvikv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1C1wk2zCwUDd"
      },
      "outputs": [],
      "source": [
        "# Check to which cue which model is trained (maybe random model)\n",
        "\n",
        "######### ATTENTION PLEASE\n",
        "pass  # please put your code instead of this line \n",
        "######### THANK YOU FOR YOUR ATTENTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEtodGSewUDe"
      },
      "source": [
        "Okay, we understood how to evaluate models, but how to train them? For that we will use function [train.train_eval_loop](https://github.com/AlexanderRubinstein/UT-TML/blob/e3a65b74526f5ef0a7197bdc8081cb0d046e0b85/src/train.py#L235-L403).\n",
        "\n",
        "To train and eval a model we will need to provide train and validation dataloaders accompanied by\n",
        "the following factories:\n",
        "\n",
        "- make_model\n",
        "- make_metrics\n",
        "- make_criterion\n",
        "- make_optimizer\n",
        "- make_scheduler\n",
        "\n",
        "as well as function \"do_train_func\" which defines how to update model weights (you can see examples of these functions in the next task).\n",
        "\n",
        "With these building blocks we can describe any train/eval procedure we need."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDXXakgHwUDe"
      },
      "source": [
        "### Train a model (3 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69hl4XyiwUDe"
      },
      "outputs": [],
      "source": [
        "one_cue_train_dataloader = datasets.prepare_default_dsprites_dataloaders_maker(\n",
        "    one_dataloader_to_select=GROUND_TRUTH_CUE\n",
        ")(None)\n",
        "\n",
        "model_to_train = models.prepare_resnet18_maker()()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-1t7g8iwUDe"
      },
      "source": [
        "Train the \"model_to_train\" on the \"one_cue_train_dataloader\" and validate on the \"test_multilabel_dataloaders\" so that it has 90%+ validation accuracy.\n",
        "\n",
        "Use the following functions from the UT-TML repo:\n",
        "- [train.train_eval_loop](https://github.com/AlexanderRubinstein/UT-TML/blob/e3a65b74526f5ef0a7197bdc8081cb0d046e0b85/src/train.py#L235-L403)\n",
        "- [train.make_accuracy](https://github.com/AlexanderRubinstein/UT-TML/blob/e3a65b74526f5ef0a7197bdc8081cb0d046e0b85/src/train.py#L451-L452)\n",
        "- [train.make_ce_criterion](https://github.com/AlexanderRubinstein/UT-TML/blob/e3a65b74526f5ef0a7197bdc8081cb0d046e0b85/src/train.py#L455-L456)\n",
        "- [train.prepare_sgd_optimizer_maker](https://github.com/AlexanderRubinstein/UT-TML/blob/e3a65b74526f5ef0a7197bdc8081cb0d046e0b85/src/train.py#L459-L468)\n",
        "- [train.prepare_exp_scheduler_maker](https://github.com/AlexanderRubinstein/UT-TML/blob/e3a65b74526f5ef0a7197bdc8081cb0d046e0b85/src/train.py#L490-L495)\n",
        "- [train.do_default_train_func](https://github.com/AlexanderRubinstein/UT-TML/blob/e3a65b74526f5ef0a7197bdc8081cb0d046e0b85/src/train.py#L498-L563)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juPqUSRYwUDe"
      },
      "outputs": [],
      "source": [
        "######### ATTENTION PLEASE\n",
        "pass  # please put your code instead of this line \n",
        "######### THANK YOU FOR YOUR ATTENTION"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To avoid calling above function every time, in the next exercises we will use function [experiments.generic_experiment](https://github.com/AlexanderRubinstein/UT-TML/blob/e3a65b74526f5ef0a7197bdc8081cb0d046e0b85/src/experiments.py#L13-L86). It will train and eval model on train/val dataloaders and then test it on a test dataloader. It will use factories to create all objects."
      ],
      "metadata": {
        "id": "2Cz68uvwqD4D"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9xjpptUwUDe"
      },
      "source": [
        "## 1.5 De-biasing task (10 + 5 + 5 + 10 + 15 [+ 10] = 45 [55] points)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the de-biasing task we will focus on two cues. One cue will be called \"ground_truth_cue\" (defined by the \"GROUND_TRUTH_CUE\") and the second cue will be called \"easy_to_bias_cue\" (defined by the \"EASY_TO_BIAS_CUE\"). "
      ],
      "metadata": {
        "id": "jAjzry-xmCdn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each sample will be assigned with two labels: \"ground_truth_label\" according to the \"ground_truth_cue\" and \"easy_to_bias_label\" according to the \"easy_to_bias_cue\"."
      ],
      "metadata": {
        "id": "I7-72mGzmnwB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's introduce the concept of diagonal and off-diagonal samples:"
      ],
      "metadata": {
        "id": "4x7c8tSxNbXF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1tlRWcMEY0TWG4E9eb161GuX3qJvzI4QS \"Diagonal and off-diagonal samples.\")"
      ],
      "metadata": {
        "id": "2v6utGWag6Ss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see from the image above, when \"ground_truth_label\" equals \"easy_to_bias_label\" for some sample, this sample is called diagonal, otherwise it is called off-diagonal."
      ],
      "metadata": {
        "id": "UNEyF1i9nVio"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFGiz56PwUDe"
      },
      "source": [
        "\n",
        "\n",
        "Most of the samples in the train dataloader will be diagonal in this exercise. \n",
        "\n",
        "Our goal is to to train a model which predicts \"ground_truth_label\" with higher accuracy than \"easy_to_bias_label\". The main difficulty is that it is not a necessary condition for correctly predicting train labels."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see what happens if we just train a model on a purely diagonal train dataloader (i.e. all samples are diagonal in this dataloader)."
      ],
      "metadata": {
        "id": "WLCXfeebpumD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM7XYEEzwUDe"
      },
      "source": [
        "For that reason we will use a function \"de_biasing_exp\" below. It uses [datasets.prepare_de_biasing_task_dataloader_maker](https://github.com/AlexanderRubinstein/UT-TML/blob/e3a65b74526f5ef0a7197bdc8081cb0d046e0b85/src/datasets.py#L966-L1123) to prepare factories for dataloaders. If you are interested, there is a comment about validation and test datasets for this experiment in the \"Note\" section of the [report task](https://colab.research.google.com/drive/1rBbUwaaugOOCEt5eOQnSe9q4INdU5SoN#scrollTo=WLqrYkopwUDh&line=16&uniqifier=1) description."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qymDuHFwUDf"
      },
      "outputs": [],
      "source": [
        "def de_biasing_exp(\n",
        "    n_epochs,\n",
        "    make_train_dataloader=datasets.prepare_de_biasing_task_dataloader_maker(),\n",
        "    make_val_dataloaders=datasets.prepare_de_biasing_task_dataloader_maker(\n",
        "        split=\"test\",\n",
        "        dataset_size=TEST_DATASET_SIZE\n",
        "    ),\n",
        "    make_test_dataloaders=datasets.prepare_default_dsprites_dataloaders_maker(\n",
        "        is_multilabel=True,\n",
        "        split=\"test\",\n",
        "        dataset_size=TEST_DATASET_SIZE\n",
        "    ),\n",
        "    make_model=models.prepare_resnet18_maker(),\n",
        "    make_criterion=train.make_ce_criterion,\n",
        "    make_optimizer=train.prepare_sgd_optimizer_maker(DEFAULT_START_LR),\n",
        "    make_scheduler=train.prepare_exp_scheduler_maker(),\n",
        "    make_metric=train.make_accuracy,\n",
        "    do_train_func=train.do_default_train_func,\n",
        "    random_seed=RANDOM_SEED,\n",
        "    stop_after_epoch=None\n",
        "):\n",
        "\n",
        "    experiments.generic_experiment(\n",
        "        n_epochs=n_epochs,\n",
        "        make_train_dataloader=make_train_dataloader,\n",
        "        make_val_dataloaders=make_val_dataloaders,\n",
        "        make_test_dataloaders=make_test_dataloaders,\n",
        "        make_model=make_model,\n",
        "        make_metric=make_metric,\n",
        "        make_criterion=make_criterion, \n",
        "        make_optimizer=make_optimizer,\n",
        "        make_scheduler=make_scheduler,\n",
        "        do_train_func=do_train_func,\n",
        "        random_seed=random_seed,\n",
        "        stop_after_epoch=stop_after_epoch\n",
        "    )\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fO4gfHBwUDf"
      },
      "source": [
        "Let's run default de-biasing exp:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdX54_l7wUDf"
      },
      "outputs": [],
      "source": [
        "de_biasing_exp(n_epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMl7UDgMwUDf"
      },
      "source": [
        "As we can see the model trained during this experiment is indeed biased to the \"easy_to_bias_cue\". Let's add some off-diagonal samples to the train dataloader:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCFrckk7wUDf"
      },
      "outputs": [],
      "source": [
        "de_biasing_exp(\n",
        "    make_train_dataloader=datasets.prepare_de_biasing_task_dataloader_maker(\n",
        "        off_diag_proportion=OFF_DIAG_PROPORTION\n",
        "    ),\n",
        "    n_epochs=10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2rLJBWiwUDf"
      },
      "source": [
        "New model is less biased to the \"easy_to_bias_cue\" but is still far from predicting the \"ground_truth_cue\" correctly. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What about using a custom loss that treats diagonal and off-diagonal samples differently?"
      ],
      "metadata": {
        "id": "YX-APVe2HHw3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAmp-a1vwUDf"
      },
      "source": [
        "### Apply diagonal and off-diagonal weights in \"WeightedCrossEntropy\" loss. (10 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76sIlOe1wUDf"
      },
      "outputs": [],
      "source": [
        "class WeightedCrossEntropy:\n",
        "    \"\"\"\n",
        "    Class for the modification of the cross entropy loss \n",
        "    which has different weights for diagonal and off-diagonal loss elements.\n",
        "\n",
        "    Where i-th loss element is L(x_i, y_i),\n",
        "    when (x_i, y_i) is the i-th sample, \n",
        "    i.e. x_i and y_i are i-th input and ground truth label correspondingly,\n",
        "    and L(x, y) -> R is some loss function.\n",
        "\n",
        "    Loss element is called diagonal (off-diagonal) \n",
        "        if it is computed for the diagonal (off-diagonal) sample.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, \n",
        "        off_diag_weight: float, \n",
        "        diag_weight: float\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize WeightedCrossEntropy.\n",
        "\n",
        "        Args:\n",
        "            off_diag_weight (float): a weight given to the off-diagonal \n",
        "                loss elements. \n",
        "                Stored in \"self.off_diag_weight\".\n",
        "\n",
        "            diag_weight (float): a weight given to the diagonal loss elements.\n",
        "                Stored in \"self.diag_weight\".\n",
        "        \"\"\"\n",
        "\n",
        "        self.off_diag_weight = off_diag_weight\n",
        "        self.diag_weight = diag_weight\n",
        "        self.ce = torch.nn.CrossEntropyLoss(reduction=\"none\") \n",
        "        self.use_second_labels = True\n",
        "\n",
        "    def apply_weights(\n",
        "        self, \n",
        "        unreduced_loss: torch.tensor, \n",
        "        ground_truth_labels: torch.tensor, \n",
        "        easy_to_bias_labels: torch.tensor\n",
        "    ) -> torch.tensor:\n",
        "        \"\"\"\n",
        "        Apply \"self.off_diag_weight\" to the off-diagonal loss elements \n",
        "        and \"self.diag_weight\" to the diagonal loss elements. \n",
        "        Then compute mean value of all loss elements. \n",
        "\n",
        "        Args:\n",
        "\n",
        "            unreduced_loss (torch.tensor): \n",
        "                a sequence of loss elements for each sample in a batch, \n",
        "                i.e. [L(x_i, y_i)]_i.\n",
        "\n",
        "            ground_truth_labels (torch.tensor):\n",
        "                a sequence of ground truth labels, i.e. [y_i]_i.\n",
        "\n",
        "            easy_to_bias_labels (torch.tensor):\n",
        "                a sequence of labels assigned \n",
        "                according to the \"easy to bias\" cue.\n",
        "\n",
        "        Returns: \n",
        "            loss (torch.tensor): mean value of loss elements \n",
        "                after applying corresponding weights to the diagonal \n",
        "                and off-diagonal loss elements.\n",
        "        \"\"\"\n",
        "\n",
        "        ######### ATTENTION PLEASE\n",
        "        pass  # please put your code instead of this line \n",
        "        ######### THANK YOU FOR YOUR ATTENTION\n",
        "\n",
        "    def __call__(self, pred, ground_truth_labels, easy_to_bias_labels):\n",
        "\n",
        "        unreduced_loss = self.ce(pred, ground_truth_labels)\n",
        "        \n",
        "        return self.apply_weights(\n",
        "            unreduced_loss, \n",
        "            ground_truth_labels, \n",
        "            easy_to_bias_labels\n",
        "        )\n",
        "\n",
        "\n",
        "def prepare_weighted_ce_maker(off_diag_weight, diag_weight):\n",
        "    \n",
        "    def make_weighted_ce():\n",
        "        return WeightedCrossEntropy(off_diag_weight, diag_weight)\n",
        "\n",
        "    return make_weighted_ce"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xde1wvz4wUDf"
      },
      "source": [
        "Now we will run an experiment with a weighted loss that uses \"INVERTED_OFF_DIAG_PROPORTION\" as a weight for the off-diag samples (we use an ADAM optimizer here, its factory function is made by function [train.prepare_adam_optimizer_maker](https://github.com/AlexanderRubinstein/UT-TML/blob/e3a65b74526f5ef0a7197bdc8081cb0d046e0b85/src/train.py#L471-L487)):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_BiENKpwUDf"
      },
      "outputs": [],
      "source": [
        "de_biasing_exp(\n",
        "    n_epochs=20,\n",
        "    make_train_dataloader=datasets.prepare_de_biasing_task_dataloader_maker(\n",
        "        off_diag_proportion=OFF_DIAG_PROPORTION\n",
        "    ),\n",
        "    make_criterion=prepare_weighted_ce_maker(INVERTED_OFF_DIAG_PROPORTION, 1),\n",
        "    make_optimizer=train.prepare_adam_optimizer_maker(0.01)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-R3b0vrwUDf"
      },
      "source": [
        "Modifying loss is quite an useful approach, but it sounds not sophisticated enough. Why don't we try Domain-Adversarial Training of Neural Networks (DANN) method inspired by [this paper](https://arxiv.org/abs/1505.07818)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "row1iQ_uwUDg"
      },
      "source": [
        "To implement this approach we will use the \"ResNetWrapperForDANN\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgoElcyhwUDg"
      },
      "outputs": [],
      "source": [
        "class ResNetWrapperForDANN:\n",
        "    \"\"\"\n",
        "    A wrapper for ResNet18 model to prepare it for the DANN method.\n",
        "    It has a feature extractor \"self.Gf\", \n",
        "    a \"ground_truth\" label predictor head \"self.Gy\"\n",
        "    and an \"easy_to_bias\" label predictor head \"self.Gd\" \n",
        "    (a substitution for the domain predictor from the DANN paper, \n",
        "    that is why \"d\").\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, resnet_model):\n",
        "\n",
        "        self.Gf = torch.nn.Sequential(\n",
        "            resnet_model.conv1, \n",
        "            resnet_model.bn1, \n",
        "            resnet_model.relu,\n",
        "            resnet_model.maxpool,\n",
        "            resnet_model.layer1,\n",
        "            resnet_model.layer2,\n",
        "            resnet_model.layer3, \n",
        "            resnet_model.layer4,\n",
        "            resnet_model.avgpool\n",
        "        )\n",
        "\n",
        "        in_features = resnet_model.fc.in_features\n",
        "        out_features = resnet_model.fc.out_features\n",
        "\n",
        "        self.Gy = torch.nn.Linear(in_features, out_features)\n",
        "        self.Gd = torch.nn.Linear(in_features, out_features)\n",
        "\n",
        "        self.is_train = True\n",
        "\n",
        "    def __call__(self, input):\n",
        "\n",
        "        features = self.Gf(input)\n",
        "        features = features.transpose(3, 1) \n",
        "\n",
        "        Gy_output = self.Gy(features).squeeze()\n",
        "\n",
        "        if self.is_train:\n",
        "            return Gy_output, self.Gd(features).squeeze()\n",
        "        else:\n",
        "            return Gy_output\n",
        "\n",
        "    def train(self):\n",
        "        self.is_train = True\n",
        "        self.Gf.train()\n",
        "        self.Gy.train()\n",
        "        self.Gd.train() \n",
        "\n",
        "    def eval(self):\n",
        "        self.is_train = False\n",
        "        self.Gf.eval()\n",
        "        self.Gy.eval()\n",
        "        self.Gd.eval() \n",
        "\n",
        "    def to(self, device):\n",
        "        self.Gf.to(device)\n",
        "        self.Gy.to(device)\n",
        "        self.Gd.to(device)\n",
        "\n",
        "\n",
        "def make_resnet_18_for_DANN():\n",
        "    return ResNetWrapperForDANN(models.prepare_resnet18_maker()())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYeB39vnwUDg"
      },
      "source": [
        "The idea of this approach is to simultaneously update weights of feature extractor \"Gf\" to both decrease loss (increase accuracy) for \"ground_truth_cue\" head \"Gy\" and increase loss (decrease accuracy) for \"easy_to_bias_cue\" head \"Gd\". \n",
        "\n",
        "In an ideal case after this adversarial training, \"Gf\" will extract such features that will be informative for distinguishing \"ground_truth_cue\" and totally non-informative for distinguishing \"easy_to_bias_cue\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMxl5jPZwUDg"
      },
      "source": [
        "For this increase-decrease (adversarial) task we will use a pair of optimizers. One will be using gradients of loss for Gy predictions, another will be using gradients of loss for Gd predictions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuAYxMcDwUDg"
      },
      "source": [
        "### Choose which parameters which optimizer should update (5 points):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SxOb4w1wUDg"
      },
      "outputs": [],
      "source": [
        "class OptimizerForDANN:\n",
        "    \"\"\"\n",
        "    An optimizer for the DANN method. Contains two sub-optimizers: \n",
        "    \n",
        "      - self.Gy_loss_optimizer for both Gy_loss \n",
        "        and inverted (multiplied by -1) Gd_loss.\n",
        "\n",
        "      - self.Gd_loss_optimizer for only Gd_loss. \n",
        "\n",
        "    Even though self.Gy_loss_optimizer optimizes Gy_loss and inverted Gd_loss,\n",
        "    for name simplicity reasons it does not contain Gd_loss in its name\n",
        "    (losses are explained in \"CriterionForDann\").\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, \n",
        "        model, \n",
        "        optimizer_constructor,\n",
        "        lr,\n",
        "        **optimizer_kwargs\n",
        "    ):\n",
        "\n",
        "        assert isinstance(model, ResNetWrapperForDANN)\n",
        "\n",
        "        featurizer_params = list(\n",
        "            filter(lambda p: p.requires_grad, model.Gf.parameters())\n",
        "        )\n",
        "        Gy_predictor_params = list(\n",
        "            filter(lambda p: p.requires_grad, model.Gy.parameters())\n",
        "        )\n",
        "        Gd_predictor_params = list(\n",
        "            filter(lambda p: p.requires_grad, model.Gd.parameters())\n",
        "        )\n",
        "\n",
        "        self.Gy_loss_optimizer_params, self.Gd_loss_optimizer_params \\\n",
        "            = self.assign_params_to_optimizers(\n",
        "                featurizer_params, \n",
        "                Gy_predictor_params, \n",
        "                Gd_predictor_params\n",
        "            )\n",
        "        \n",
        "        self.start_lr = lr\n",
        "        self.Gy_loss_optimizer = optimizer_constructor(\n",
        "            self.Gy_loss_optimizer_params,\n",
        "            lr=lr,\n",
        "            **optimizer_kwargs\n",
        "        ) \n",
        "        self.Gd_loss_optimizer = optimizer_constructor(\n",
        "            self.Gd_loss_optimizer_params,  \n",
        "            lr=lr,\n",
        "            **optimizer_kwargs\n",
        "        )\n",
        "\n",
        "    def assign_params_to_optimizers(\n",
        "        self, \n",
        "        featurizer_params: List[torch.tensor], \n",
        "        Gy_predictor_params: List[torch.tensor], \n",
        "        Gd_predictor_params: List[torch.tensor]\n",
        "    ) -> Tuple[List[torch.tensor], List[torch.tensor]]:\n",
        "        \"\"\"\n",
        "        Choose which params of \"ResNetWrapperForDANN\" model\n",
        "        each optimizer should optimize.\n",
        "        \n",
        "        Args:\n",
        "            featurizer_params (List[torch.tensor]): \n",
        "                params of the featurizer (model.Gf).\n",
        "\n",
        "            Gy_predictor_params (List[torch.tensor]): \n",
        "                params of the ground truth label predictor head (model.Gy).\n",
        "\n",
        "            Gd_predictor_params (List[torch.tensor]): \n",
        "                params of the easy to bias label predictor head (model.Gd).\n",
        "\n",
        "        Returns:\n",
        "        \n",
        "            Gy_loss_optimizer_params (List[torch.tensor]): params \n",
        "                for the self.Gy_loss_optimizer suboptimizer.\n",
        "\n",
        "            Gd_loss_optimizer_params (List[torch.tensor]): params \n",
        "                for the self.Gd_loss_optimizer suboptimizer.\n",
        "        \"\"\"\n",
        "\n",
        "        ######### ATTENTION PLEASE\n",
        "        pass  # please put your code instead of this line \n",
        "        ######### THANK YOU FOR YOUR ATTENTION\n",
        "        \n",
        "        return Gy_loss_optimizer_params, Gd_loss_optimizer_params\n",
        "\n",
        "    def zero_grad(self):\n",
        "        self.Gy_loss_optimizer.zero_grad()\n",
        "        self.Gd_loss_optimizer.zero_grad()\n",
        "\n",
        "\n",
        "def prepare_optimizer_for_DANN_maker(\n",
        "    optimizer_constructor=optim.SGD,\n",
        "    lr=DEFAULT_START_LR,\n",
        "    **optimizer_kwargs\n",
        "):\n",
        "\n",
        "    def make_optimizer_for_DANN(model):\n",
        "        return OptimizerForDANN(\n",
        "            model, \n",
        "            optimizer_constructor,\n",
        "            lr,\n",
        "            **optimizer_kwargs\n",
        "        )\n",
        "\n",
        "    return make_optimizer_for_DANN\n",
        "\n",
        "\n",
        "# scheduler similar to the one in the paper\n",
        "class SchedulerForDANN:\n",
        "\n",
        "    def __init__(self, optimizer, alpha=ALPHA, beta=BETA):\n",
        "        assert isinstance(optimizer, OptimizerForDANN)\n",
        "        self.optimizer = optimizer\n",
        "        self.start_lr = self.optimizer.start_lr\n",
        "        self.alpha = alpha \n",
        "        self.beta = beta \n",
        "        self.training_progress = 0\n",
        "        self.step()\n",
        "\n",
        "    def step(self):\n",
        "        denominator = (1 + self.alpha * self.training_progress) ** self.beta\n",
        "        current_lr = self.start_lr / denominator\n",
        "        self.optimizer.Gd_loss_optimizer.param_groups[0]['lr'] = current_lr\n",
        "        self.optimizer.Gy_loss_optimizer.param_groups[0]['lr'] = current_lr\n",
        "        \n",
        "        \n",
        "def prepare_scheduler_for_DANN_maker(alpha, beta):\n",
        "\n",
        "    def make_scheduler_for_DANN(optimizer):\n",
        "        return SchedulerForDANN(optimizer, alpha, beta)\n",
        "\n",
        "    return make_scheduler_for_DANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1nfxzMGwUDg"
      },
      "source": [
        "### How to compute \"Gy_loss\" and \"Gd_loss\" for the DANN criterion? (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeQFtfDOwUDg"
      },
      "outputs": [],
      "source": [
        "class CriterionForDANN:\n",
        "    \"\"\"\n",
        "    Compute loss for predictions of \"model.Gy\" \n",
        "    and \"ground truth labels\" (Gy_loss) \n",
        "    as well as loss for predictions of \"model.Gd\"\n",
        "    and \"easy to bias labels\" (Gd_loss).\n",
        "    Where model is of type \"ResNetWrapperForDANN\".\n",
        "\n",
        "    \"self.f_lambda\" is a weight with which negative Gd_loss is used \n",
        "    to compute gradients for \"model.Gf\".\n",
        "\n",
        "    \"self.d_lambda\" is a weight with which Gd_loss is used \n",
        "    to compute gradients for \"model.Gd\".\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, Gd_loss_weight, gamma):\n",
        "        self.ce = train.make_ce_criterion()\n",
        "        self.f_lambda = 0\n",
        "        self.d_lambda = Gd_loss_weight \n",
        "        self._training_progress = 0\n",
        "        self.gamma = gamma\n",
        "        self.use_second_labels = True\n",
        "\n",
        "    @property\n",
        "    def training_progress(self):\n",
        "        return self._training_progress\n",
        "\n",
        "    @training_progress.setter\n",
        "    def training_progress(self, new_value):\n",
        "        self._training_progress = new_value\n",
        "        self._update_f_lambda()\n",
        "\n",
        "    # update for loss weights similar to the one in the paper\n",
        "    def _update_f_lambda(self):\n",
        "        assert self.training_progress >= 0\n",
        "        assert self.training_progress <= 1\n",
        "        self.f_lambda = (\n",
        "            2 * torch.sigmoid(\n",
        "                torch.Tensor([self.gamma * self.training_progress])\n",
        "            ).item() - 1\n",
        "        )\n",
        "\n",
        "    def __call__(self, pred, ground_truth_labels, easy_to_bias_labels):\n",
        "\n",
        "        def compute_losses(\n",
        "            compute_loss: Callable,\n",
        "            Gy_pred: torch.tensor, \n",
        "            Gd_pred: torch.tensor, \n",
        "            ground_truth_labels: torch.tensor, \n",
        "            easy_to_bias_labels: torch.tensor\n",
        "        ) -> Tuple[torch.tensor, torch.tensor]:\n",
        "            \"\"\"\n",
        "            Compute Gy_loss and Gd_loss.\n",
        "\n",
        "            Args:\n",
        "\n",
        "                compute_loss (Callable): function used to compute loss \n",
        "                    for predictions and labels.\n",
        "\n",
        "                Gy_pred (torch.tensor): predictions by model.Gy.\n",
        "\n",
        "                Gd_pred (torch.tensor): predictions by model.Gd.\n",
        "\n",
        "                ground_truth_labels (torch.tensor): cameo.\n",
        "\n",
        "                easy_to_bias_labels (torch.tensor): cameo.\n",
        "\n",
        "            Returns:\n",
        "\n",
        "                Gy_loss (torch.tensor): cameo.\n",
        "\n",
        "                Gd_loss (torch.tensor): cameo.\n",
        "            \"\"\"\n",
        "            ######### ATTENTION PLEASE\n",
        "            pass  # please put your code instead of this line \n",
        "            ######### THANK YOU FOR YOUR ATTENTION\n",
        "            \n",
        "            return Gy_loss, Gd_loss\n",
        "\n",
        "        assert len(pred) == 2, \\\n",
        "            \"Expect target predictor output and domain predictor output\" \n",
        "\n",
        "        Gy_pred, Gd_pred = pred\n",
        "\n",
        "        Gy_loss, Gd_loss = compute_losses(\n",
        "            self.ce,\n",
        "            Gy_pred, \n",
        "            Gd_pred, \n",
        "            ground_truth_labels, \n",
        "            easy_to_bias_labels\n",
        "        )\n",
        "\n",
        "        return Gy_loss, Gd_loss, self.f_lambda, self.d_lambda\n",
        "\n",
        "\n",
        "def prepare_criterion_for_DANN_maker(Gd_loss_weight=D_LAMBDA, gamma=GAMMA):\n",
        "\n",
        "    def make_criterion_for_DANN():\n",
        "        return CriterionForDANN(Gd_loss_weight, gamma)\n",
        "\n",
        "    return make_criterion_for_DANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LHmk2_pwUDg"
      },
      "source": [
        "### How to properly update weights of the model in \"do_dann_train_func\"? (10 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9eR1PuTwUDg"
      },
      "outputs": [],
      "source": [
        "def do_dann_train_func(\n",
        "    model: torch.nn.Module,\n",
        "    criterion: Callable,\n",
        "    optimizer: object,\n",
        "    images_batch: torch.tensor,\n",
        "    labels_batch: torch.tensor,\n",
        "    second_labels_batch: torch.tensor,\n",
        "    epoch_histories: Dict[str, List[float]]\n",
        ") -> Tuple[torch.tensor, Dict[str, List[float]]]:\n",
        "    \"\"\"\n",
        "    <do_train_func> for UT-TML repo function \"train.run_epoch\" \n",
        "        in a DANN scenario.\n",
        "\n",
        "    Args and Returns:\n",
        "\n",
        "        same as for UT-TML repo function \"train.do_default_train\".\n",
        "    \"\"\"\n",
        "\n",
        "    def do_optimizer_steps(\n",
        "        optimizer: OptimizerForDANN, \n",
        "        total_loss: torch.tensor, \n",
        "        weighted_Gd_loss: torch.tensor\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Perform steps by the \"OptimizerForDann\"'s suboptimizers. \n",
        "        One optimizes <total_loss> another optimizes <weighted_Gd_loss>.\n",
        "        Where <total_loss> and <weighted_Gd_loss> have been computed using \n",
        "        Gy_loss and Gd_loss returned by the \"CriterionForDANN\".\n",
        "\n",
        "        Args:\n",
        "            optimizer (OptimizerForDann): \"OptimizerForDann\" which will update \n",
        "                model weights using gradients from the <total_loss> \n",
        "                and the <weighted_Gd_loss>.\n",
        "\n",
        "            total_loss (torch.tensor): loss term computed \n",
        "                as Gy_loss - \"CriterionForDANN\".f_lambda * Gd_loss.\n",
        "\n",
        "            weighted_Gd_loss (torch.tensor): loss term computed \n",
        "                as \"CriterionForDANN\".d_lambda * Gd_loss\n",
        "        \"\"\"\n",
        "\n",
        "        ######### ATTENTION PLEASE\n",
        "        pass  # please put your code instead of this line \n",
        "        ######### THANK YOU FOR YOUR ATTENTION\n",
        "    \n",
        "    assert isinstance(optimizer, OptimizerForDANN), \\\n",
        "        \"Optimizer should be OptimizerForDANN\"\n",
        "    assert isinstance(criterion, CriterionForDANN), \\\n",
        "        \"Criterion should be CriterionForDANN\"\n",
        "\n",
        "    pred_batch = model(images_batch)\n",
        "\n",
        "    Gy_loss, Gd_loss, f_lambda, d_lambda = criterion(\n",
        "        pred_batch, \n",
        "        labels_batch, \n",
        "        second_labels_batch\n",
        "    )\n",
        "    total_loss = Gy_loss - f_lambda * Gd_loss\n",
        "    weighted_Gd_loss = d_lambda * Gd_loss\n",
        "\n",
        "    do_optimizer_steps(optimizer, total_loss, weighted_Gd_loss)\n",
        "\n",
        "    utils.append_to_list_in_dict(\n",
        "        epoch_histories, \n",
        "        \"total_loss\", \n",
        "        total_loss.item()\n",
        "    )\n",
        "    utils.append_to_list_in_dict(\n",
        "        epoch_histories, \n",
        "        \"Gy_loss\", \n",
        "        Gy_loss.item()\n",
        "    )\n",
        "    utils.append_to_list_in_dict(\n",
        "        epoch_histories, \n",
        "        \"Gd_loss\", \n",
        "        Gd_loss.item()\n",
        "    )\n",
        "    \n",
        "    return pred_batch[0], epoch_histories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3awsoEowUDh"
      },
      "source": [
        "Let's run debiasing experiment using DANN method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ienkk1W-wUDh"
      },
      "outputs": [],
      "source": [
        "de_biasing_exp(\n",
        "    n_epochs=100,\n",
        "    make_train_dataloader=datasets.prepare_de_biasing_task_dataloader_maker(\n",
        "        off_diag_proportion=OFF_DIAG_PROPORTION,\n",
        "        batch_size=128\n",
        "    ),\n",
        "    make_model=make_resnet_18_for_DANN,\n",
        "    make_optimizer=prepare_optimizer_for_DANN_maker(lr=0.001),\n",
        "    make_criterion=prepare_criterion_for_DANN_maker(Gd_loss_weight=1, gamma=10),\n",
        "    make_scheduler=prepare_scheduler_for_DANN_maker(alpha=ALPHA, beta=BETA),\n",
        "    do_train_func=do_dann_train_func\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLqrYkopwUDh"
      },
      "source": [
        "### Report (15 points)\n",
        "\n",
        "We want to answer the research question: whether DANN or weighted loss method is better for the de-biasing task?\n",
        "\n",
        "Make an argument below, based on empirical evidence, which approach is \"better\"?\n",
        "\n",
        "For answering this question, consider the following aspects:\n",
        "- Accuracy.\n",
        "- Computational complexity.\n",
        "  - Space and time.\n",
        "  - Training and inference.\n",
        "- Fairness of hyperparameter tuning and model choice.\n",
        "\n",
        "Feel free to run additional model training experiments to support your argument (hyperparameters used for the above experiments were not tuned, so you can tune them).\n",
        "\n",
        "Note: please take into account that validation and test data for this task both contain the same images but different labels, therefore hyperparameters you might tune will be overfitted not only to validation data but also to test data, but in this exercise it is okay."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUQMmmaLwUDh"
      },
      "source": [
        "### Bonus questions (5 + 5 = 10 points)\n",
        "\n",
        "- **BQ1** By using the argument \"off_diag_multiplier\" for function [datasets.prepare_de_biasing_task_dataloader_maker](https://github.com/AlexanderRubinstein/UT-TML/blob/e3a65b74526f5ef0a7197bdc8081cb0d046e0b85/src/datasets.py#L966-L1123) we can add duplicates of off-diagonal samples to the train dataloader to artificially increase off-diagonal samples proportion in each batch. Provide experiments on comparing this approach to the approach that uses \"WeightedCrossEntropy\" (increasing number of off-diagonal samples vs increasing weight for off-diagonal samples). Give some intuition explaining the results. **(5 points)**\n",
        "\n",
        "- **BQ2** Empirically disclose relation between learning rate and \"WeightedCrossEntropy.off_diag_weight\", make a guess how they are interconnected and under which circumstances. **(5 points)**.  \n",
        "Please do the following:\n",
        "    - Conduct experiments comparing changes in the learning rate and \"off_diag_weight\".\n",
        "    - Explain their interconnection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLmuVscqwUDh"
      },
      "source": [
        "## 1.6 Adversarial attacks (5 + 5 + 5 + 5 + 7 = 27 points)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGSL7qmvwUDh"
      },
      "source": [
        "Now let's think about a distribution shift caused by an adversarial attack. By an attack we will understand such an addition of noise to the image that maximizes loss for the model's prediction and the correct label.\n",
        "\n",
        "To better understand how attacks work let's implement the [Fast Gradient Sign Method (FGSM)](https://arxiv.org/abs/1412.6572) attack.\n",
        "\n",
        "Our goal in this exercise is to train a model that will be able to predict labels according to the \"ADVERSARIALLY_ATTACKED_CUE\" even under the FGSM attack."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1WHzfC-wUDh"
      },
      "source": [
        "### Compute adversarial images inside \"AttackFGSM.\\_\\_call\\_\\_\" method **(5 points)**:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AttackFGSM:\n",
        "    \"\"\"\n",
        "    Class for a Fast Gradient Sign Method (FGSM) attack.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, \n",
        "        eps: float, \n",
        "        criterion: Callable\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize FGSM attack.\n",
        "\n",
        "        Args:\n",
        "\n",
        "            eps (float): an argument for nested function \n",
        "                \"compute_adversarial_images\" in the \"__call__\" method \n",
        "                of this class. \n",
        "                Stored in the \"self.eps\".\n",
        "\n",
        "            criterion (Callable): a function to compute the <loss> argument \n",
        "                for nested function \"compute_adversarial_images\" \n",
        "                in the \"__call__\" method of this class.\n",
        "                Stored in the \"self.criterion\".\n",
        "        \"\"\"\n",
        "        self.eps = eps\n",
        "        self.criterion = criterion\n",
        "\n",
        "    def __call__(\n",
        "        self,\n",
        "        images: torch.tensor, \n",
        "        labels: torch.tensor, \n",
        "        model: torch.nn.Module = None, \n",
        "        outputs: torch.tensor = None,\n",
        "        retain_graph: bool = False,\n",
        "    ) -> torch.tensor:\n",
        "        \n",
        "        \"\"\"\n",
        "        Perform a FGSM attack by computing adversarial images. \n",
        "\n",
        "        Args:\n",
        "\n",
        "            self.*: see the \"__init__\" method of this class.\n",
        "\n",
        "            images (torch.tensor): input images to attack.\n",
        "\n",
        "            labels (torch.tensor): labels for the <images>.\n",
        "\n",
        "            model (torch.nn.Module, optional): a model which outputs \n",
        "                are used for loss computation; \n",
        "                gradients of this loss w.r.t. to the <images> \n",
        "                will be used by the attack. \n",
        "                If it is None, <outputs> should be provided directly.\n",
        "                Default: None\n",
        "\n",
        "            outputs (torch.tensor, optional): outputs of the attacked model. \n",
        "                The <images> and the <outputs> should be in the same \n",
        "                computational graph.\n",
        "                This argument is used to avoid calling the same model \n",
        "                on the same images more than one time.\n",
        "                If it is None, then <model> should be provided \n",
        "                to compute outputs inside this method.\n",
        "                Default: None\n",
        "\n",
        "            retain_graph (bool): \n",
        "                an argument for nested function \"compute_adversarial_images\".\n",
        "                Default: False\n",
        "\n",
        "        Returns:\n",
        "\n",
        "            adv_images (torch.tensor): images returned \n",
        "                by nested function \"compute_adversarial_images\" of this method. \n",
        "            \n",
        "        \"\"\"\n",
        "\n",
        "        def compute_adversarial_images(\n",
        "            images: torch.tensor, \n",
        "            eps: float, \n",
        "            loss: torch.tensor, \n",
        "            retain_graph: bool\n",
        "        ) -> torch.tensor:\n",
        "            \"\"\"\n",
        "            Compute adversarial images (adv_images) using FGSM\n",
        "            as adv_images = <images> + <eps> * grad_sign. \n",
        "\n",
        "            Where \n",
        "\n",
        "                grad_sign - sign of the <loss>'s gradient \n",
        "                    w.r.t. to the <images>. \n",
        "\n",
        "            Args:\n",
        "\n",
        "                images (torch.tensor): original images.\n",
        "\n",
        "                eps (float): an attack parameter reflecting the magnitude \n",
        "                    of an attack.\n",
        "\n",
        "                loss (torch.tensor): a loss which gradients \n",
        "                    are used for an attack.\n",
        "\n",
        "                retain_graph (bool): a flag, if it is True, \n",
        "                    then gradient computational graph,\n",
        "                    built during the <loss> computation, will be retained \n",
        "                    after computing a gradient in the current function.\n",
        "                    Otherwise it will be deleted.\n",
        "\n",
        "            Returns:\n",
        "\n",
        "                adv_images (torch.tensor): adversarial images. \n",
        "            \"\"\"\n",
        "            \n",
        "            ######### ATTENTION PLEASE\n",
        "            pass  # please put your code instead of this line \n",
        "            ######### THANK YOU FOR YOUR ATTENTION\n",
        "            \n",
        "            return adv_images\n",
        "\n",
        "        assert not (outputs is None and model is None)\n",
        "        \n",
        "        device = (\n",
        "            outputs.device \n",
        "                if model is None\n",
        "                else next(iter(model.parameters())).device\n",
        "        )\n",
        "        \n",
        "        labels = labels.to(device)\n",
        "\n",
        "        if outputs is None:\n",
        "\n",
        "            images = images.clone().detach().to(device)\n",
        "            images.requires_grad = True\n",
        "            outputs = model(images)\n",
        "\n",
        "        else:\n",
        "            \n",
        "            assert images.requires_grad\n",
        "\n",
        "        loss = self.criterion(outputs, labels)\n",
        "\n",
        "        adv_images = compute_adversarial_images(\n",
        "            images, \n",
        "            self.eps, \n",
        "            loss, \n",
        "            retain_graph\n",
        "        )\n",
        "\n",
        "        adv_images = torch.clamp(adv_images, min=0, max=1).detach()\n",
        "\n",
        "        return adv_images"
      ],
      "metadata": {
        "id": "l439NKI9LY6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY9l1aDNwUDh"
      },
      "source": [
        "To make a use of already existing dataloaders we can create an adversarial dataloader by substituting images in a normal dataloader by the adversarial ones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zv6bL6UUwUDh"
      },
      "source": [
        "### Swap images with adversarial images in method \"AdversarialAttackDataloaderWrapper.\\_\\_next\\_\\_\" **(5 points)**:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AdversarialAttackDataloaderWrapper:\n",
        "    \"\"\"\n",
        "    A wrapper for an underlying dataloader\n",
        "    that generates adversarial images and labels \n",
        "    by attacking images generated by the underlying dataloader.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self, \n",
        "        dataloader: torch.utils.data.DataLoader, \n",
        "        attack: Callable, \n",
        "        model: torch.nn.Module\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize the dataloader wrapper.\n",
        "\n",
        "        Args:\n",
        "\n",
        "            dataloader (torch.utils.data.DataLoader): underlying dataloader.\n",
        "                Stored in \"self.dataloader\".\n",
        "\n",
        "            attack (Callable): an attack used for attacking images.\n",
        "                Stored in \"self.attack\".\n",
        "\n",
        "            model (torch.nn.Module): an argument for method \"<attack>.__call__\".\n",
        "                Stored in \"self.model\".\n",
        "        \"\"\"\n",
        "\n",
        "        self.dataloader = dataloader\n",
        "        self.dataloader_iterator = iter(self.dataloader)\n",
        "        self.attack = attack\n",
        "        self.model = model\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "\n",
        "        try:\n",
        "            dataloader_item = next(self.dataloader_iterator)\n",
        "        except StopIteration as e:\n",
        "            self.dataloader_iterator = iter(self.dataloader)\n",
        "            raise e\n",
        "\n",
        "        assert len(dataloader_item) >= 2\n",
        "\n",
        "        images = dataloader_item[0]\n",
        "        labels = dataloader_item[1]\n",
        "\n",
        "        adv_images, labels \\\n",
        "            = self.swap_images_by_adversarial_images(images, labels)\n",
        "        \n",
        "        dataloader_item[0] = adv_images\n",
        "        dataloader_item[1] = labels\n",
        "\n",
        "        return dataloader_item\n",
        "\n",
        "    def swap_images_by_adversarial_images(\n",
        "        self, \n",
        "        images: torch.tensor, \n",
        "        labels: torch.tensor\n",
        "    ) -> Tuple[torch.tensor, torch.tensor]:\n",
        "        \"\"\"\n",
        "        Take images and labels generated by the underlying dataloader \n",
        "        and swap images by the adversarial ones.\n",
        "\n",
        "        Args:\n",
        "\n",
        "            self.*: see method \"__init__\" for the current class.\n",
        "\n",
        "            images (torch.tensor): original images \n",
        "                generated by the underlying dataloader.\n",
        "\n",
        "            labels (torch.tensor): labels for the <images>.\n",
        "\n",
        "        Returns:\n",
        "\n",
        "            adv_images (torch.tensor): adversarial images.\n",
        "\n",
        "            labels (torch.tensor): labels for the <adv_images>\n",
        "                (the same as for the <images>).\n",
        "        \"\"\"\n",
        "\n",
        "        ######### ATTENTION PLEASE\n",
        "        pass  # please put your code instead of this line \n",
        "        ######### THANK YOU FOR YOUR ATTENTION\n",
        "\n",
        "        return adv_images, labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataloader)"
      ],
      "metadata": {
        "id": "LdIEIFYoMcxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzt8ySyuwUDh"
      },
      "source": [
        "Now we are ready to create a factory for adversarial dataloader:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_adversarial_dataloader_maker(\n",
        "    dsprites_holder_args: Dict[str, Any] = DEFAULT_DSPRITES_HOLDER_ARGS,\n",
        "    target_cue: str = ADVERSARIALLY_ATTACKED_CUE, \n",
        "    split: str = \"train\", \n",
        "    dataset_size: int = TRAIN_DATASET_SIZE,\n",
        "    shuffle: bool = True,\n",
        "    attack: Callable \\\n",
        "        = AttackFGSM(eps=FGSM_EPS, criterion=train.make_ce_criterion())\n",
        ") -> Callable:\n",
        "    \"\"\"\n",
        "    Prepare a factory function that creates an \"adversarial_dataloader\".\n",
        "\n",
        "    \"adversarial_dataloader\" is created \n",
        "    by wrapping a \"default_dsprites_dataloader\" into\n",
        "    \"AdversarialAttackDataloaderWrapper\".\n",
        "\n",
        "    Where \"default_dsprites_dataloader\" is created by\n",
        "    a factory function prepared by UT-TML repo function \n",
        "    \"datasets.prepare_default_dsprites_dataloaders_maker\"\n",
        "\n",
        "    Args:\n",
        "\n",
        "        dsprites_holder_args, split, dataset_size, shuffle: same arguments \n",
        "            as for UT-TML repo function \n",
        "            \"datasets.prepare_default_dsprites_dataloaders_maker\".\n",
        "            Default values are the same as in that function.\n",
        "\n",
        "        target_cue (str): a name of the cue according to which labels are given.\n",
        "            It means that underlying dataloader factory function is prepared \n",
        "            with arg \"one_dataloader_to_select\" equal to the <target_cue>.\n",
        "            Default: ADVERSARIALLY_ATTACKED_CUE\n",
        "\n",
        "        attack (Callable): an attack \n",
        "            used for initializing \"AdversarialAttackDataloaderWrapper\".\n",
        "            Default: AttackFGSM(\n",
        "                eps=FGSM_EPS, \n",
        "                criterion=train.make_ce_criterion()\n",
        "            )\n",
        "\n",
        "    Returns:\n",
        "        a factory function that takes model as an argument\n",
        "        and creates adversarial dataloader in the following format:\n",
        "\n",
        "            - Dict[str, torch.utils.data.DataLoader]: a dictionary\n",
        "                that maps \"adversarial_dataloader_name\" to the dataloader \n",
        "                which generates:\n",
        "                    - images adversarial w.r.t. the given model. \n",
        "                    - labels according to the <target_cue>.\n",
        "                \n",
        "                Where \"adversarial_dataloader_name\" is made \n",
        "                    by concatenating \"adversarial_\" + <target_cue>. \n",
        "    \"\"\"\n",
        "\n",
        "    def make_adversarial_dataloaders(model):\n",
        "\n",
        "        one_cue_dataloader \\\n",
        "            = datasets.prepare_default_dsprites_dataloaders_maker(\n",
        "                dsprites_holder_args=dsprites_holder_args,\n",
        "                one_dataloader_to_select=target_cue,\n",
        "                split=split,\n",
        "                dataset_size=dataset_size,\n",
        "                shuffle=shuffle\n",
        "            )(None)\n",
        "\n",
        "        return { \n",
        "            \"adversarial_\" + target_cue: AdversarialAttackDataloaderWrapper(\n",
        "                dataloader=one_cue_dataloader,\n",
        "                attack=attack,\n",
        "                model=model\n",
        "            )\n",
        "        }\n",
        "    \n",
        "    return make_adversarial_dataloaders"
      ],
      "metadata": {
        "id": "OvzGblLQM64E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caIZQ-eEwUDi"
      },
      "source": [
        "Let's take a look at adversarial samples with respect to the first model we trained in the [dSpritesIntroduction](https://colab.research.google.com/drive/1rBbUwaaugOOCEt5eOQnSe9q4INdU5SoN#scrollTo=69hl4XyiwUDe&line=2&uniqifier=1):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGvksySzwUDi"
      },
      "outputs": [],
      "source": [
        "adv_test_dataloaders = prepare_adversarial_dataloader_maker(\n",
        "    target_cue=GROUND_TRUTH_CUE\n",
        ")(model_to_train)\n",
        "\n",
        "# this loop is here because \n",
        "# adv_test_dataloaders = {\"adversarial_dataloader_name\": adversarial_dataloader}\n",
        "for adversarial_dataloader_name, adversarial_dataloader \\\n",
        "    in adv_test_dataloaders.items():\n",
        "\n",
        "    utils.show_dataloader_first_batch(\n",
        "        adversarial_dataloader, \n",
        "        [adversarial_dataloader_name]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCw4BoRawUDi"
      },
      "source": [
        "Just like in the de-biasing task we can create an experiment function that uses default factories.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8WeOlalwUDi"
      },
      "outputs": [],
      "source": [
        "def adversarial_exp(\n",
        "    n_epochs,\n",
        "    make_train_dataloader=datasets.prepare_default_dsprites_dataloaders_maker(\n",
        "        one_dataloader_to_select=ADVERSARIALLY_ATTACKED_CUE\n",
        "    ), \n",
        "    make_val_dataloaders=prepare_adversarial_dataloader_maker(\n",
        "        split=\"test\",\n",
        "        dataset_size=TEST_DATASET_SIZE\n",
        "    ), \n",
        "    make_test_dataloaders=datasets.prepare_default_dsprites_dataloaders_maker(\n",
        "        is_multilabel=True,\n",
        "        split=\"test\",\n",
        "        dataset_size=TEST_DATASET_SIZE\n",
        "    ),\n",
        "    make_model=models.prepare_resnet18_maker(), \n",
        "    make_criterion=train.make_ce_criterion, \n",
        "    do_train_func=train.do_default_train_func,\n",
        "    make_optimizer=train.prepare_sgd_optimizer_maker(DEFAULT_START_LR),\n",
        "    make_scheduler=train.prepare_exp_scheduler_maker(),\n",
        "    make_metric=train.make_accuracy,\n",
        "    random_seed=RANDOM_SEED,\n",
        "    stop_after_epoch=None\n",
        "):\n",
        "\n",
        "    experiments.generic_experiment(\n",
        "        n_epochs=n_epochs,\n",
        "        make_train_dataloader=make_train_dataloader,\n",
        "        make_val_dataloaders=make_val_dataloaders,\n",
        "        make_test_dataloaders=make_test_dataloaders,\n",
        "        make_model=make_model,\n",
        "        make_metric=make_metric,\n",
        "        make_criterion=make_criterion, \n",
        "        make_optimizer=make_optimizer,\n",
        "        make_scheduler=make_scheduler,\n",
        "        do_train_func=do_train_func,\n",
        "        random_seed=random_seed,\n",
        "        stop_after_epoch=stop_after_epoch\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KpPxfRvwUDi"
      },
      "source": [
        "Let's run a default adversarial experiment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovHwTZvUwUDi"
      },
      "outputs": [],
      "source": [
        "adversarial_exp(\n",
        "    n_epochs=10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3V5TSiqHwUDi"
      },
      "source": [
        "Adversarial accuracy for \"ADVERSARIALLY_ATTACKED_CUE\" on validation dataset is lower than random guess accuracy. We can try to increase it by performing adversarial training.  \n",
        "\n",
        "To achieve this we need the following:\n",
        "\n",
        "- adversarial criterion.\n",
        "- do_adversarial_train_func ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79AFWSv1wUDi"
      },
      "source": [
        "Let's start with the adversarial criterion. It needs to compute adversarial input and use it for the computation of an adversarial loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxxYFUkPwUDi"
      },
      "source": [
        "### Compute adversarial loss in method \"CriterionForAdversarialAttack.\\_\\_call\\_\\_\" **(5 points)**:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CriterionForAdversarialAttack:\n",
        "    \n",
        "    def __init__(\n",
        "        self, \n",
        "        attack: Callable,\n",
        "        alpha: float,\n",
        "        criterion: Callable\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize criterion for adversarial training.\n",
        "\n",
        "        Args:\n",
        "\n",
        "            attack (Callable): same as \n",
        "                for \"AdversarialAttackDataloaderWrapper.__init__\" method.\n",
        "                Stored in \"self.attack\".\n",
        "\n",
        "            alpha (float): an argument that will be used \n",
        "                by function \"do_adversarial_train\".\n",
        "                Stored in \"self.alpha\".\n",
        "\n",
        "            criterion (Callable): a function used for computing loss \n",
        "                for images and labels, or adversarial images \n",
        "                and the same labels in method \"__call__\" of this class.\n",
        "                Stored in \"self.criterion\".\n",
        "        \"\"\"\n",
        "        self.attack = attack\n",
        "        self.alpha = alpha\n",
        "        self.criterion = criterion\n",
        "\n",
        "    def __call__(self, model, images, label):\n",
        "\n",
        "        images.requires_grad = True\n",
        "        pred = model(images)\n",
        "        target_loss = self.criterion(pred, label)\n",
        "\n",
        "        adversarial_loss = self.compute_adversarial_loss(\n",
        "            model, \n",
        "            images, \n",
        "            label, \n",
        "            pred\n",
        "        )\n",
        "\n",
        "        return pred, target_loss, adversarial_loss, self.alpha\n",
        "\n",
        "    def compute_adversarial_loss(\n",
        "        self, \n",
        "        model: torch.nn.Module, \n",
        "        images: torch.tensor, \n",
        "        labels: torch.tensor, \n",
        "        preds: torch.tensor\n",
        "    ) -> torch.tensor:\n",
        "        \"\"\"\n",
        "        Compute an adversarial loss as L(adv_images, labels).\n",
        "        Where \"adv_images\" are images attacked \n",
        "        by the \"self.attack\" (adversarial images),\n",
        "        \"labels\" are labels for this images \n",
        "        (they are the same as for the unattacked images) \n",
        "        and \"L\" is \"self.criterion\".\n",
        "\n",
        "        Args:\n",
        "\n",
        "            self.*: see \"__init__\" method of this class.\n",
        "\n",
        "            model (torch.nn.Module): a model \n",
        "                used to compute predictions for adversarial images.\n",
        "\n",
        "            images (torch.tensor): input images that are attacked.\n",
        "\n",
        "            labels (torch.tensor): labels for the <images> as well as \n",
        "                for the \"adv_images\".\n",
        "\n",
        "            preds (torch.tensor): outputs of the <model> \n",
        "                after <images> are forwarded through it. \n",
        "                They are already computed because they were used \n",
        "                for the \"target_loss\" computation.\n",
        "\n",
        "                Where \"target_loss\" is an argument \n",
        "                for nested function \"do_optimizer_step\"\n",
        "                inside function \"do_adversarial_train\".\n",
        "\n",
        "        Returns:\n",
        "\n",
        "            adversarial_loss (torch.tensor): cameo\n",
        "        \"\"\"\n",
        "        \n",
        "        ######### ATTENTION PLEASE\n",
        "        pass  # please put your code instead of this line \n",
        "        ######### THANK YOU FOR YOUR ATTENTION\n",
        "\n",
        "        return adversarial_loss\n",
        "\n",
        "\n",
        "def prepare_criterion_for_adversarial_attack_maker(\n",
        "    attack, \n",
        "    alpha,\n",
        "    criterion\n",
        "):\n",
        "    \n",
        "    def make_criterion_for_adversarial_attack():\n",
        "        return CriterionForAdversarialAttack(\n",
        "            attack, \n",
        "            alpha,\n",
        "            criterion\n",
        "        )\n",
        "\n",
        "    return make_criterion_for_adversarial_attack"
      ],
      "metadata": {
        "id": "EDUh_gHBNPe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbqXNPoUwUDi"
      },
      "source": [
        "Speaking about \"do_adversarial_train\", it should be similar to [do_default_train](https://github.com/AlexanderRubinstein/UT-TML/blob/e3a65b74526f5ef0a7197bdc8081cb0d046e0b85/src/train.py#L498-L563) with modifications to the way the final loss is computed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXROOMYKwUDi"
      },
      "source": [
        "### Compute final loss using outputs of the \"CriterionForAdversarialAttack\" and update model's weights **(5 points)**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMUSUvj0wUDi"
      },
      "outputs": [],
      "source": [
        "def do_adversarial_train(\n",
        "    model, \n",
        "    criterion, \n",
        "    optimizer, \n",
        "    images, \n",
        "    labels, \n",
        "    second_labels,  # needed for compatibility with de-biasing exp\n",
        "    epoch_histories\n",
        "):\n",
        "\n",
        "    def do_optimizer_step(\n",
        "        alpha: float, \n",
        "        target_loss: torch.tensor, \n",
        "        adversarial_loss: torch.tensor, \n",
        "        optimizer: object\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Compute the final loss as described in paper \n",
        "        \"EXPLAINING AND HARNESSING ADVERSARIAL EXAMPLES\"\n",
        "        [https://arxiv.org/pdf/1412.6572.pdf].\n",
        "        Use its gradients to update the <model>'s weigths.\n",
        "\n",
        "        Args:\n",
        "\n",
        "            alpha (float): a weight for combining losses.\n",
        "\n",
        "            target_loss (torch.tensor): a loss for the original task, \n",
        "                i.e. in the absence of any adversarial attacks.\n",
        "\n",
        "            adversarial_loss (torch.tensor): a loss computed \n",
        "                by method \"compute_adversarial_loss\" \n",
        "                of class \"CriterionForAdversarialAttack\".\n",
        "\n",
        "            optimizer (optimizer class): an optimizer \n",
        "                that updates model's weights.\n",
        "        \"\"\"\n",
        "\n",
        "        ######### ATTENTION PLEASE\n",
        "        pass  # please put your code instead of this line \n",
        "        ######### THANK YOU FOR YOUR ATTENTION\n",
        "\n",
        "    assert isinstance(criterion, CriterionForAdversarialAttack)\n",
        "    \n",
        "    pred, target_loss, adversarial_loss, alpha = criterion(\n",
        "        model, \n",
        "        images, \n",
        "        labels\n",
        "    )\n",
        "\n",
        "    do_optimizer_step(alpha, target_loss, adversarial_loss, optimizer)\n",
        "\n",
        "    utils.append_to_list_in_dict(\n",
        "        epoch_histories, \n",
        "        \"target_loss\", \n",
        "        target_loss.item()\n",
        "    )\n",
        "    utils.append_to_list_in_dict(\n",
        "        epoch_histories, \n",
        "        \"adversarial_loss\", \n",
        "        adversarial_loss.item()\n",
        "    )\n",
        "\n",
        "    return pred, epoch_histories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "181ZRA0nwUDi"
      },
      "source": [
        "Let's run an experiment using adversarial training (we use an ADAM optimizer just like in WeightedCrossEntropy exercise for the de-biasing task):"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adversarial_exp(\n",
        "    n_epochs=10,\n",
        "    make_criterion=prepare_criterion_for_adversarial_attack_maker(\n",
        "        attack=AttackFGSM(eps=FGSM_EPS, criterion=train.make_ce_criterion()), \n",
        "        alpha=FGSM_ALPHA,\n",
        "        criterion=train.make_ce_criterion()\n",
        "    ),\n",
        "    do_train_func=do_adversarial_train,\n",
        "    make_optimizer=train.prepare_adam_optimizer_maker(0.01)\n",
        ")\n"
      ],
      "metadata": {
        "id": "eTscN0VgNe0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb6nkwtnwUDj"
      },
      "source": [
        "### Report **(7 points)**\n",
        "\n",
        "Which pros and cons has adversarial training with respect to vanilla training? \n",
        "\n",
        "For answering this question, consider the following aspects:\n",
        "- Clean and adversarial accuracy.\n",
        "- Computational complexity.\n",
        "- Can you guarantee your safety against arbitrary adversarial attacks after performing adversarial training?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2xGeyGLwUDj"
      },
      "source": [
        "That's it! Good job!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('mlc-dev')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "c135a73c87a9219087d3ace32074332ecd17ca889285bc44d81a43eea8f18699"
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}