{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Trustworthy Machine Learning**\n",
        "### Winter Semester 2022-2023\n",
        "### Lecturer: Seong Joon Oh\n",
        "### **Exercise 0 -- Preliminary Materials**\n",
        "\n",
        "---\n",
        "\n",
        "Student name <input> Joschka Str√ºber\n",
        "\n",
        "Student email <input> joschka.strueber@student.uni-tuebingen.de\n",
        "\n",
        "---\n",
        "\n",
        "#### **Submission deadline: 27/10/2022 at 23:59.**\n",
        "\n",
        "Welcome to the Trustworthy Machine Learning course! TML is an advanced course that assumes some basic knowledge of machine learning and deep learning. This zeroth exercise will test your prerequisite knowledge and skills. \n",
        "\n",
        "#### **Policy for the zeroth exercise**\n",
        "This exercise is the **only individual exercise** in our course. The rest of the exercises in our course will be submitted and graded per group. The purpose of this zeroth exercise is to ensure that individual members of each group are sufficiently committed. As such, **we will enrol only the students who submit the zeroth exercise**. We will only accept solutions with the **minimal passing grade 30/100 points** to make sure that students do not submit empty work. The grade for the zeroth exercise **does not count towards the final grade**. The main purpose of this exercise is to selectively enrol motivated students and for you to evaluate your own readiness for the course. \n",
        "\n",
        "\n",
        "####**Submission**\n",
        "Follow the below four steps.\n",
        "\n",
        "(1) Copy this colab file to your local gdrive;\n",
        "\n",
        "`File > Save a copy in Drive`\n",
        "\n",
        "(2) Work on the solution on your local copy;\n",
        "\n",
        "(3) Pin the version for submission in history;\n",
        "\n",
        "`Click on \"All changes saved\" or \"Last saved at XX:XX AM/PM\" next to the drop-down menus at the top > Select version to submit > Click on three vertical dots (vertical ellipsis) > Rename > Write \"Submission\" `\n",
        "\n",
        "(4) Share your local colab with `stai.there@gmail.com` before the deadline.\n",
        "\n",
        "`Click on \"Share\" at the top-right corner > Put stai.there@gmail.com in \"Add people and groups\" > Give the \"Viewer\" right and tick on \"Notify people\" > Click send.`\n",
        "\n",
        "Note that we are able to see the edit history with time stamps, so please ensure that you stop working on your notebook before the deadline."
      ],
      "metadata": {
        "id": "QFWnwGiwu-EP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **0.1 Multivariate Calculus (10 + 10 + 5 = 25 points)**\n",
        "\n",
        "Let $f\\in\\mathbb{R}^C$ be a vector with dimension $C$, equal to the number of classes. Let $Y\\in\\{1,\\cdots,C\\}$ be the corresponding ground-truth label. We define the softmax-cross-entropy loss as follows:\n",
        "\\begin{equation}\n",
        "    \\mathcal{L} = -\\sum_{j=1}^C \\delta_{jY} \\log \\frac{\\exp{f_j}}{\\sum_k \\exp{f_k}}\n",
        "\\end{equation}\n",
        "where $\\delta_{ab}$ is the Kronecker Delta:\n",
        "\\begin{equation}\n",
        "    \\delta_{ab} = \n",
        "    \\begin{cases}\n",
        "        1\\quad \\text{if $a=b$;} \\\\\n",
        "        0\\quad \\text{otherwise;}\n",
        "    \\end{cases}\n",
        "\\end{equation}"
      ],
      "metadata": {
        "id": "FmGAkVwBwCDu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(a) Compute the gradient $\\frac{\\partial \\mathcal{L}}{\\partial f_c}$ for $c\\in\\{1,\\cdots,C\\}$. It may be helpful to introduce the substitution $p_j:=\\frac{\\exp{f_j}}{\\sum_k \\exp{f_k}}$. **(10 points)**"
      ],
      "metadata": {
        "id": "KZ0YTixTj8nD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solution:**\n",
        "\n",
        "We start by expanding the logarithm on $p_j$ and taking the partial derivative on both parts of the sum:\n",
        "\n",
        "\\begin{align}\n",
        "  \\frac{\\partial \\mathcal{L}}{\\partial f_c} &= - \\sum_{j=1}^C \\delta_{jY} \\frac{\\partial}{\\partial f_c} \\log \\left( \\frac{\\exp f_j}{\\sum_k \\exp f_k} \\right) \\\\\n",
        "  &= - \\sum_{j=1}^C \\delta_{jY} \\frac{\\partial}{\\partial f_c} \\left( f_j - \\log \\sum_k \\exp f_k \\right) \\\\\n",
        "  &= - \\sum_{j=1}^C \\delta_{jY} \\left( \\frac{\\partial f_j}{\\partial f_c} - \\frac{\\partial}{\\partial f_c} \\log \\sum_k \\exp f_k \\right) \\\\\n",
        "  &= - \\sum_{j=1}^C \\delta_{jY} \\left( \\delta_{jc} - \\frac{\\exp f_c}{\\sum_k \\exp f_k} \\right), \\\\\n",
        "\\end{align}\n",
        "\n",
        "where the last step followed by using the chain rule as well as the derivatives of the logarithmic and exponential function. Next, we use the property of products of Kronecker deltas and the definition of $p_c$:\n",
        "\n",
        "\\begin{align}\n",
        "  \\frac{\\partial \\mathcal{L}}{\\partial f_c} &= - \\sum_{j=1}^C \\delta_{jY} \\left( \\delta_{jc} - \\frac{\\exp f_c}{\\sum_k \\exp f_k} \\right), \\\\\n",
        "  &= - \\sum_{j=1}^C \\delta_{Yc} - \\delta_{jY} p_c \\\\\n",
        "  &= \\left( \\sum_{j=1}^C \\delta_{jY} \\right) p_c - \\delta_{Yc} \\\\\n",
        "  &= p_c - \\delta_{Yc}\n",
        "\\end{align}\n",
        "\n",
        "Here we used the fact that $p_c$ and $\\delta_{Yc}$ are independent of the control variable $j$ and that the sum of Kronecker deltas must be one, because $Y$ is one-hot encoded."
      ],
      "metadata": {
        "id": "JaQ1fkSBkJZP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let $\\{(X_i, Y_i)\\}_{i=1}^N$ be data samples with $X\\in\\mathbb{R}^D$ (e.g. images) and $Y\\in\\{1,\\cdots,C\\}$ (e.g. labels). Let  $f:\\mathbb{R}^I\\rightarrow\\mathbb{R}^C$ be a two-layer neural network of the following architecture\n",
        "\\begin{equation}\n",
        "    f(X;W,V) = V\\cdot \\sigma(W\\cdot X)\n",
        "\\end{equation}\n",
        "where $W\\in\\mathbb{R}^{H\\times D}$ maps $X$ to a hidden space $\\mathbb{R}^H$, $\\sigma$ is the element-wise ReLU activation function $\\sigma(x)=\\max\\{0,x\\}$, and $V\\in\\mathbb{R}^{C\\times H}$ maps a hidden representation to the output space $\\mathbb{R}^C$. Now, plug in our two-layer neural network to the $f$ in the softmax-cross-entropy loss:\n",
        "\\begin{equation}\n",
        "    \\mathcal{L}(W,V) = -\\sum_{j=1}^C \\delta_{jY} \\log \\frac{\\exp{f_j(X;W,V)}}{\\sum_k \\exp{f_k(X;W,V)}}\n",
        "\\end{equation}"
      ],
      "metadata": {
        "id": "DV6YVDILkncs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(b) Compute the gradient $\\frac{\\partial \\mathcal{L}}{\\partial V_{ch}}$ for $c\\in\\{1,\\cdots,C\\}$ and $h\\in\\{1,\\cdots,H\\}$ using the answer to (a) and chain rule. **(10 points)**"
      ],
      "metadata": {
        "id": "BImL0fBMkxZq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SOLUTION:**\n",
        "\n",
        "Using the chain rule and the partial derivative wrt. $p_c$ yields: \n",
        "\\begin{align}\n",
        "  \\frac{\\partial \\mathcal{L}}{\\partial V_{ch}} &= \\frac{\\partial \\mathcal{L}}{\\partial f_c} \\frac{\\partial f_c}{\\partial V_{ch}} \\\\\n",
        "  &= \\left( p_c - \\delta_{Yc} \\right) \\frac{\\partial f_c}{\\partial V_{ch}} \\\\\n",
        "\\end{align}\n",
        "\n",
        "It is enough to concentrate on $f_c$, because since we are looking at $V_{ch}$, we only care about the $c$-th row of the output vector, as the partial derivative wrt. $V_{ch}$ of all other ones is 0. We continue by plugging in the definition of entry $f_c$:\n",
        "\n",
        "\\begin{align}\n",
        "  \\frac{\\partial \\mathcal{L}}{\\partial V_{ch}} &= \\left( p_c - \\delta_{Yc} \\right) \\frac{\\partial f_c}{\\partial V_{ch}} \\\\\n",
        "  &= \\left( p_c - \\delta_{Yc} \\right) \\frac{\\partial}{\\partial V_{ch}} \\sum_{i=1}^H V_{ci} \\sigma(W\\cdot X)_i \\\\\n",
        "  &= \\left( p_c - \\delta_{Yc} \\right) \\sigma(W\\cdot X)_h \\\\\n",
        "\\end{align}\n"
      ],
      "metadata": {
        "id": "4fNQiEYwk2WE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(c) Compute the gradient $\\frac{\\partial \\mathcal{L}}{\\partial W_{hd}}$ for $h\\in\\{1,\\cdots,H\\}$ and $d\\in\\{1,\\cdots,D\\}$ using the answer to (b) and chain rule. **(5 points)**"
      ],
      "metadata": {
        "id": "dJu-FZ2xlDFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SOLUTION:**\n",
        "\n",
        "$W_{hd}$ is a fan-out that influences each entry of $f_c$. Therefore, we have to sum up the gradients and plug in the solution to (b).\n",
        "\n",
        "\\begin{align}\n",
        "  \\frac{\\partial \\mathcal{L}}{\\partial W_{hd}} &= \\sum_{j=1}^C \\frac{\\partial \\mathcal{L}}{\\partial V_{jh}} \\frac{\\partial V_{jh}}{\\partial W_{hd}} \\\\\n",
        "  &= \\sum_{j=1}^C \\left( p_j - \\delta_{Yj} \\right) \\sigma(W\\cdot X)_h \\frac{\\partial V_{jh}}{\\partial W_{hd}} \\\\\n",
        "  &= \\sum_{j=1}^C \\left( p_j - \\delta_{Yj} \\right) \\sigma(W\\cdot X)_h \\mathbb{1}_{\\sigma(W\\cdot X)_h > 0} X_d \\\\\n",
        "\\end{align}\n",
        "\n",
        "We used chain rule and the fact that the derivative of ReLU is either 0 or 1 and write it as indicator function.\n",
        "\n",
        "**Comment:** I'm fairly confident this solution is wrong, because for the gradient of entries of $W$, we don't need the gradient wrt. the parameters of the previous layer, $V$, but that of the compute nodes that used $V$ instead."
      ],
      "metadata": {
        "id": "YfpzFic3lGsN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **0.2 Generalisation (5 + 5 + 5 + 5 + 5 = 25 points)**\n"
      ],
      "metadata": {
        "id": "G0XM7OHjw97x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(a) What is the role of training, validation, and test splits of a dataset for machine learning? **(5 points)**\n",
        "\n",
        "**Solution:**\n",
        "\n",
        "The training set is used to train a given model with a fixed set of hyperparameters. The validation set's purpose is to evaluate such a model trained on the training set to find the best model, set of hyperparameters or point in time to stop the training via early stopping. Once a model with hyperparameters is chosen based on the performance on the test set, it can be finally evaluated on the test set. The score on the set can be used as a benchmark against other approaches.\n",
        "\n",
        "In theory, the test set must only be used to report final results and not for model selection. In practice, subsequent research is always based on models that performed well on the test sets of standards benchmarks, resulting in at least a small information leak."
      ],
      "metadata": {
        "id": "l-mbINjflcUA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WRITE YOUR SOLUTION HERE**"
      ],
      "metadata": {
        "id": "RdJXLBo3lc60"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider an image classification task, where $X\\in\\mathbb{R}^D$ is an input image and $Y\\in\\{1,\\cdots,C\\}$ is the corresponding label following $p(X,Y)$. Let $\\mathcal{D}^\\text{tr}=\\{(X_i,Y_i)\\}_{i=1}^N$ and $\\mathcal{D}^\\text{te}=\\{(X_i,Y_i)\\}_{i=N+1}^{N+M}$ be training and test samples, respectively, that are IID-sampled from $p(X,Y)$. Let $f_\\theta$ be a model trained on $\\mathcal{D}^\\text{tr}$. Write $f_\\theta(c,X)\\in[0,1]$ for the predicted probability that image $X$ belongs to class $c$."
      ],
      "metadata": {
        "id": "12uNvbjqlin6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(b) Write down the equations for the training- and test-set accuracies of $p_\\theta$. **(5 points)**\n"
      ],
      "metadata": {
        "id": "L528qOn1ljfI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solution:**\n",
        "\n",
        "\\begin{align}\n",
        "  \\operatorname{acc}_{\\operatorname{tr}} &= \\frac{1}{N} \\sum_{i=1}^N \\mathbb{1}_{\\{\\operatorname{argmax}_j(f_{\\theta}(j, X_i)) == Y_i\\}} \\\\\n",
        "  \\operatorname{acc}_{\\operatorname{te}} &= \\frac{1}{M} \\sum_{i=N+1}^{N+M} \\mathbb{1}_{\\{\\operatorname{argmax}_j(f_{\\theta}(j, X_i)) == Y_i\\}}\n",
        "\\end{align}\n",
        "\n",
        "In other words, we count the empirical mean of correct predictions as estimators for inverse of the true risk based on the 0-1-loss."
      ],
      "metadata": {
        "id": "RDsZszitlnji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(c) Explain what it means to say that $f_\\theta$ \"generalises well\" and introduce a quantitative metric for this. **(5 points)**"
      ],
      "metadata": {
        "id": "X83E1DdjlpTR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solution:**\n",
        "\n",
        "A model $f_{\\theta}$ generalizes well, if its performance on new, previously unseen data drawn from the same data distribution is just or at least almost as good as the set used for training the model.\n",
        "\n",
        "A quantitative metric for this could be the difference in performance between the training and a test or validation set:\n",
        "\n",
        "\\begin{equation}\n",
        "  \\operatorname{train\\_test\\_diff} = \\operatorname{acc}_{\\operatorname{tr}} - \\operatorname{acc}_{\\operatorname{te}}\n",
        "\\end{equation}\n",
        "\n",
        "Whether to use the unchanged, absolute or squared difference is up to debate and depends what you want to measure."
      ],
      "metadata": {
        "id": "plqcogLGltw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(d) Explain the concept of overfitting and underfitting. **(5 points)**\n"
      ],
      "metadata": {
        "id": "asxIvGjjlyqu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solution:**\n",
        "\n",
        "Overfitting happens if the model complexity is too high without counteracting regularization. The result is a model that often performs perfect or almost perfect on the training data, but fails to generalize to unseen data. This often happens when we have a high estimation error, because the model that has only seen a small subset of all possible data, learns random noise.\n",
        "\n",
        "Underfitting means that the model's complexity is not high enough and its proposed solution too simple to explain the true data distribution (eg. class boundaries). This usually happens when the chosen model class is not large and complex enough and has a high approximation error compared to the Bayes classifier."
      ],
      "metadata": {
        "id": "sfPBkF-UlzzJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(e) Explain the respective solutions for overfitting and underfitting. **(5 points)**\n"
      ],
      "metadata": {
        "id": "0Ma7ifHdl20n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solution:**\n",
        "\n",
        "The solution to overfitting is to either reduce the model complexity (eg. smaller network with less parameters and layers), use stronger regularization to prevent overcomplex solution, incorporate augmentation techniques to increase the amount of data the models sees, or use methods such as early stopping that stop the training process, when it performs best on the unseen validation set.\n",
        "\n",
        "Underfitting can be countered by using models with higher complexity. Possible approaches are using a higher (initial) learning rate, weaker regularization or a model with more layers and parameters."
      ],
      "metadata": {
        "id": "xAZchYMdl40v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **0.3 MNIST Case-study (15 + 15 + 10 + 10 = 50 points)**\n",
        "\n",
        "*This exercise is based on the public code at https://colab.research.google.com/github/skorch-dev/skorch/blob/master/notebooks/MNIST.ipynb (BSD 3-Clause License)*."
      ],
      "metadata": {
        "id": "fXn5gZIWwd7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! [ ! -z \"$COLAB_GPU\" ] && pip install torch scikit-learn==0.20.* skorch"
      ],
      "metadata": {
        "id": "dqzjwU0JzFTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import logging"
      ],
      "metadata": {
        "id": "hPp10JADzaVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Data\n",
        "\n",
        "The following code downloads MNIST. It takes 2-3 minutes."
      ],
      "metadata": {
        "id": "OjddOGaWzhsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = fetch_openml('mnist_784', cache=True)"
      ],
      "metadata": {
        "id": "Aht68ourzcik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist.data.shape"
      ],
      "metadata": {
        "id": "fRi_gw4FzeWK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "879a45a9-1017-420b-e9f7-23a42459f5cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing Data\n",
        "\n",
        "Each image of the MNIST dataset is encoded in a 784 dimensional vector, representing a 28 x 28 pixel image. Each pixel has a value between 0 and 255, corresponding to the grey-value of a pixel.<br />\n",
        "The above ```featch_mldata``` method to load MNIST returns ```data``` and ```target``` as ```uint8``` which we convert to ```float32``` and ```int64``` respectively."
      ],
      "metadata": {
        "id": "QcdCLOvyzoog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### COMMENT: had to change to numpy array, because new fetch_openml returns \n",
        "##### pandas dataframe. Result were OOM errors in the train-test-split test\n",
        "X = mnist.data.astype('float32').to_numpy()\n",
        "y = mnist.target.astype('int64').to_numpy()"
      ],
      "metadata": {
        "id": "5HOEqw3rzoL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To avoid big weights that deal with the pixel values from between [0, 255], we scale `X` down. A commonly used range is [0, 1]."
      ],
      "metadata": {
        "id": "PwRg0az8zt4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X /= 255.0"
      ],
      "metadata": {
        "id": "VaRVxh_Kzulg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.min(), X.max()"
      ],
      "metadata": {
        "id": "Rm0A8CD6zxGs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2667fb6-c20e-4ff7-d291-c756115b7b41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing Train-Val-Test Splits (15 points)\n",
        "\n",
        "Let's split the given MNIST data (70000 samples) into 3 partitions: train, val, and test. Complete the function `train_test_split` **(15 points)**."
      ],
      "metadata": {
        "id": "BtrbiHPrD9yO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(X, y, val_size, test_size, random_seed=None):\n",
        "  \"\"\"\n",
        "  Given a labelled dataset in memory, return two disjoint partitions, train and test, randomly split according to the given test_size.\n",
        "  For replicability, make sure that the same random_seed returns the same split of the dataset.\n",
        "  Args:\n",
        "    X: numpy.ndarray of shape (N, D) and type np.float32. N is the number of sample instances and D is the dimensionality of input features.\n",
        "    y: numpy.ndarray of shape (N,) and type np.int64.\n",
        "    val_size: float value between 0 and 1. Controls the ratio of val samples.\n",
        "    test_size: float value between 0 and 1. Controls the ratio of test samples.\n",
        "    random_seed: int or None. If it is int, set the random seed to ensure replicability. If it is None, do not set the random seed.\n",
        "  Returns:\n",
        "    dict of\n",
        "      X_train: numpy.ndarray of shape (N - L - M, D) and type np.float32.\n",
        "      y_train: numpy.ndarray of shape (N - L - M,) and type np.int64.\n",
        "      X_val: numpy.ndarray of shape (L, D) and type np.float32. L = int(N * val_size).\n",
        "      y_val: numpy.ndarray of shape (L,) and type np.int64.\n",
        "      X_test: numpy.ndarray of shape (M, D) and type np.float32. M = int(N * test_size).\n",
        "      y_test: numpy.ndarray of shape (M,) and type np.int64.\n",
        "  \"\"\"\n",
        "  #### >>>> PUT YOUR SOLUTION HERE <<<< 15 points\n",
        "  # shuffle data and targets in unison\n",
        "  rng = np.random.default_rng(seed=random_seed)\n",
        "  N, D = X.shape\n",
        "\n",
        "  # I think this works as intended, but runs out of memory on colab:\n",
        "  \"\"\"\n",
        "  cat = np.c_[X,y]\n",
        "  np.random.shuffle(cat)\n",
        "\n",
        "  X_sh, y_sh = cat[:,:X.shape[1]], cat[:,-1]\n",
        "  print(cat.shape, X_sh.shape, y_sh.shape)\n",
        "  \"\"\"\n",
        "\n",
        "  # different approach that resets RNG state and uses in-place shuffling\n",
        "  idx = np.arange(N)\n",
        "  rng.shuffle(idx)\n",
        "\n",
        "  # get the indices separating train, val and test sets\n",
        "  L = int(N * val_size)\n",
        "  M = int(N * test_size)\n",
        "\n",
        "  # split the data into the three different sets\n",
        "  X_train = X[idx[:N-L-M]]\n",
        "  y_train = y[idx[:N-L-M]]\n",
        "\n",
        "  X_val = X[idx[N-L-M:N-M]]\n",
        "  y_val = y[idx[N-L-M:N-M]]\n",
        "\n",
        "  X_test = X[idx[N-M:]]\n",
        "  y_test = y[idx[N-M:]]\n",
        "\n",
        "  #### >>>> ENT OF YOUR SOLUTION <<<<\n",
        "  return {\n",
        "      \"X_train\": X_train,\n",
        "      \"y_train\": y_train,\n",
        "      \"X_val\": X_val,\n",
        "      \"y_val\": y_val,\n",
        "      \"X_test\": X_test,\n",
        "      \"y_test\": y_test,\n",
        "  }"
      ],
      "metadata": {
        "id": "UvhnvEe10wlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define test functions."
      ],
      "metadata": {
        "id": "Fll3Ze71E-46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_diff_matrix(mat1, mat2, max_samples):\n",
        "  \"\"\"\n",
        "  Compute the pairwise L1 distance among the feature vectors in mat1 and mat2.\n",
        "  Args:\n",
        "    mat1: array of shape (N, D) where D is the feature dimension.\n",
        "    mat2: array of shape (M, D)\n",
        "    max_samples: for the interest of RAM usage, we may restrict the max number of samples\n",
        "  Returns:\n",
        "    dist_mat: array of shape (N, M) where N <- min(max_samples, N) and M <- min(max_samples, M)\n",
        "  \"\"\"\n",
        "  num_samples1 = min(max_samples, len(mat1))\n",
        "  num_samples2 = min(max_samples, len(mat2))\n",
        "  diff_matrix = np.abs(\n",
        "      np.expand_dims(mat1[:num_samples1], axis=0) # (1, N, D)\n",
        "    - np.expand_dims(mat2[:num_samples2], axis=1) # (M, 1, D)\n",
        "  ).sum(axis=2)\n",
        "  return diff_matrix\n",
        "\n",
        "\n",
        "def train_test_split_test(X, y):\n",
        "  print(f\"Checking train-val-test split sizes.\")\n",
        "  data_splits = train_test_split(X, y, val_size=0.2, test_size=0.5, random_seed=None)\n",
        "  assert(len(data_splits[\"X_train\"]) == 21000)\n",
        "  assert(len(data_splits[\"X_val\"]) == 14000)\n",
        "  assert(len(data_splits[\"X_test\"]) == 35000)\n",
        "  assert(len(data_splits[\"y_train\"]) == 21000)\n",
        "  assert(len(data_splits[\"y_val\"]) == 14000)\n",
        "  assert(len(data_splits[\"y_test\"]) == 35000)\n",
        "  data_splits = train_test_split(X, y, val_size=0.1, test_size=0.8, random_seed=None)\n",
        "  assert(len(data_splits[\"X_train\"]) == 7000)\n",
        "  assert(len(data_splits[\"X_val\"]) == 7000)\n",
        "  assert(len(data_splits[\"X_test\"]) == 56000)\n",
        "  assert(len(data_splits[\"y_train\"]) == 7000)\n",
        "  assert(len(data_splits[\"y_val\"]) == 7000)\n",
        "  assert(len(data_splits[\"y_test\"]) == 56000)\n",
        "\n",
        "  print(f\"Checking train-test split purity.\")\n",
        "  diff_matrix_tr_te = compute_diff_matrix(mat1=data_splits[\"X_train\"],\n",
        "                                          mat2=data_splits[\"X_test\"],\n",
        "                                          max_samples=1000)\n",
        "  assert(diff_matrix_tr_te.min() > 0)\n",
        "  diff_matrix_tr_val = compute_diff_matrix(mat1=data_splits[\"X_train\"],\n",
        "                                           mat2=data_splits[\"X_val\"],\n",
        "                                           max_samples=1000)\n",
        "  assert(diff_matrix_tr_val.min() > 0)\n",
        "  diff_matrix_te_val = compute_diff_matrix(mat1=data_splits[\"X_test\"],\n",
        "                                           mat2=data_splits[\"X_val\"],\n",
        "                                           max_samples=1000)\n",
        "  assert(diff_matrix_te_val.min() > 0)\n",
        "\n",
        "  print(f\"Checking whether random seed is working.\")\n",
        "  data_splits1 = train_test_split(X, y, val_size=0.1, test_size=0.3, random_seed=65)\n",
        "  data_splits2 = train_test_split(X, y, val_size=0.1, test_size=0.3, random_seed=65)\n",
        "  data_splits3 = train_test_split(X, y, val_size=0.1, test_size=0.3, random_seed=66)\n",
        "  data_splits4 = train_test_split(X, y, val_size=0.1, test_size=0.3, random_seed=None)\n",
        "  data_splits5 = train_test_split(X, y, val_size=0.1, test_size=0.3, random_seed=None)\n",
        "  \n",
        "  assert((data_splits1[\"X_train\"]==data_splits2[\"X_train\"]).all())\n",
        "  assert((data_splits2[\"X_train\"]!=data_splits3[\"X_train\"]).any())\n",
        "  assert((data_splits4[\"X_train\"]!=data_splits5[\"X_train\"]).any())"
      ],
      "metadata": {
        "id": "upTtGa8HE7eK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test your solution by running the test function below."
      ],
      "metadata": {
        "id": "CddjJDafllCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_test_split_test(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xS1WumsDkHP-",
        "outputId": "336363d1-6e47-4150-8a1b-b4ec1317bd05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking train-val-test split sizes.\n",
            "Checking train-test split purity.\n",
            "Checking whether random seed is working.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_splits = train_test_split(X, y, val_size=0.1, test_size=0.1, random_seed=42)"
      ],
      "metadata": {
        "id": "bSl_We9Tz0Kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in data_splits:\n",
        "  print(f\"{key} shape: {data_splits[key].shape}\")"
      ],
      "metadata": {
        "id": "_vTSvDQZz5dU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fed43e0-3b7c-4f23-b2bc-8d85d834f71d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (56000, 784)\n",
            "y_train shape: (56000,)\n",
            "X_val shape: (7000, 784)\n",
            "y_val shape: (7000,)\n",
            "X_test shape: (7000, 784)\n",
            "y_test shape: (7000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_example(X, y, num_samples=10):\n",
        "    \"\"\"Plot the first N images and their labels in a row.\"\"\"\n",
        "    for i, (img, y) in enumerate(zip(X[:num_samples].reshape(num_samples, 28, 28), y[:num_samples])):\n",
        "        plt.subplot(1, num_samples, i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title(y)"
      ],
      "metadata": {
        "id": "zgYMhzTBz9N9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_example(data_splits[\"X_train\"], data_splits[\"y_train\"])"
      ],
      "metadata": {
        "id": "6SSITy7R0ALB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "7f5d09df-9745-4bfb-ab1e-105e77f77ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define an MLP Model\n",
        "Simple, fully connected neural network with one hidden layer. Input layer has 784 dimensions (28x28), hidden layer has 98 (= 784 / 8) and output layer 10 neurons, representing digits 0 - 9."
      ],
      "metadata": {
        "id": "5TOSzJD-06fS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "4SJhz-4606JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "xnExi2at0-9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AfA6jDFX4fEG",
        "outputId": "278ce39c-204c-4659-b22f-78f2783cb861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_dim,\n",
        "            hidden_dim,\n",
        "            output_dim,\n",
        "            dropout=0.5,\n",
        "    ):\n",
        "        super(MLP, self).__init__()\n",
        "        print(f\"input_dim={input_dim}, hidden_dim={hidden_dim}, output_dim={output_dim}\")\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
        "        self.output = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, X, **kwargs):\n",
        "        X = F.relu(self.hidden(X))\n",
        "        X = self.dropout(X)\n",
        "        # This softmax probably shouldn't be here, since we are supposed to \n",
        "        # implement SoftmaxCrossEntropyLoss, right?\n",
        "        X = F.softmax(self.output(X), dim=-1)\n",
        "        return X"
      ],
      "metadata": {
        "id": "evkViHmF1Gyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the Loss Function (15 points)\n",
        "\n",
        "We train the model with the softmax-cross-entropy loss. The first part of the function is already there.\n",
        "```\n",
        "outputs = outputs - outputs.max(1, keepdim=True)[0]\n",
        "```\n",
        "This part ensures the numerical stability of the softmax operation, which is translation invariant.\n",
        "```\n",
        "labels_onehot = F.one_hot(labels, num_classes=10)\n",
        "```\n",
        "This part turns the integer labels into one-hot vectors.\n",
        "\n",
        "Complete the loss function **(15 points)**."
      ],
      "metadata": {
        "id": "q9ezQK5mEvvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SoftmaxCrossEntropyLoss(nn.Module):\n",
        "  def forward(self, outputs, labels):\n",
        "    \"\"\"\n",
        "    Compute softmax cross-entropy loss.\n",
        "    Args:\n",
        "      outputs: Torch.Tensor of shape (B, C) and type float32.\n",
        "      labels: Torch.Tensor of shape (B,) and type long.\n",
        "    Returns:\n",
        "      loss: Torch.Tensor of scalar shape and type float32.\n",
        "    \"\"\"\n",
        "    outputs = outputs - outputs.max(1, keepdim=True)[0]\n",
        "    labels_onehot = F.one_hot(labels, num_classes=10) # shape (B, C) type bool\n",
        "\n",
        "    #### >>>> PUT YOUR SOLUTION HERE <<<< 15 points\n",
        "    preds = torch.exp(outputs)\n",
        "    preds = preds / torch.sum(preds, dim=0)\n",
        "    loss_elem = - labels_onehot * torch.log(preds)\n",
        "    loss = loss_elem.mean()\n",
        "    #### >>>> ENT OF YOUR SOLUTION <<<<\n",
        "    return loss"
      ],
      "metadata": {
        "id": "TSmFhsy1Ey5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Solver\n",
        "\n",
        "A programming framework that is often used to manage model training, inference, and evaluation is the Solver object. This is advantageous because such activities around a model share common data and methods: \n",
        "- Model (torch.nn.Module)\n",
        "- Dataset (torch.utils.data.Dataset)\n",
        "\n",
        "We have defined the Solver class for you. You may find this framework useful for managing ML code later on."
      ],
      "metadata": {
        "id": "ey7IKKQrGU1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Solver(object):\n",
        "  def __init__(self, data_splits, model, criterion, config):\n",
        "    self.config = config\n",
        "    self.model = model\n",
        "    self.criterion = criterion\n",
        "    self.optimizer = optim.SGD(self.model.parameters(),\n",
        "                               lr=config[\"lr\"],\n",
        "                               momentum=config[\"momentum\"])\n",
        "    self.data_splits = data_splits\n",
        "\n",
        "  def load_dataloader(self, split, role):\n",
        "    if role == \"eval\":\n",
        "      batch_size = config[\"eval_batch_size\"]\n",
        "      shuffle = True\n",
        "    elif role == \"train\":\n",
        "      batch_size = config[\"batch_size\"]\n",
        "      shuffle = False\n",
        "    else:\n",
        "      raise ValueError(f\"Unknown role name {role}.\")\n",
        "    \n",
        "    return torch.utils.data.DataLoader(\n",
        "      torch.utils.data.TensorDataset(\n",
        "          torch.from_numpy(self.data_splits[f\"X_{split}\"]),\n",
        "          torch.from_numpy(self.data_splits[f\"y_{split}\"])\n",
        "      ), \n",
        "      batch_size=batch_size,\n",
        "      shuffle=shuffle,\n",
        "      num_workers=config[\"num_workers\"])\n",
        "\n",
        "  def fit_one_batch(self, inputs, labels):\n",
        "    self.optimizer.zero_grad()\n",
        "    outputs = self.model(inputs)\n",
        "    loss = self.criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    self.optimizer.step()\n",
        "    return loss\n",
        "\n",
        "  def fit_one_epoch(self, epoch_idx):\n",
        "    loss_epoch = 0.0\n",
        "    dataloader = self.load_dataloader(split=\"train\", role=\"train\")\n",
        "    for batch_idx, (inputs, labels) in enumerate(dataloader):\n",
        "      loss = self.fit_one_batch(inputs, labels)\n",
        "      loss_epoch += loss.item()\n",
        "    loss_epoch /= batch_idx + 1\n",
        "    print(f\"train_loss {loss_epoch: 2.3f}\", end=\"\\t\")\n",
        "\n",
        "  def fit(self, evaluate_on):\n",
        "    for epoch_idx in range(self.config[\"num_epochs\"]):\n",
        "      print(f\"epoch {epoch_idx + 1:03d}\", end=\"\\t\")\n",
        "      self.fit_one_epoch(epoch_idx)\n",
        "      accuracy = self.evaluate(evaluate_on)\n",
        "      print(f\"val_accuracy: {accuracy: 2.3f}%\", end=\"\\t\")\n",
        "      print()\n",
        "\n",
        "  def evaluate(self, evaluate_on):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    dataloader = self.load_dataloader(split=evaluate_on, role=\"eval\")\n",
        "    with torch.no_grad():\n",
        "      for (inputs, labels) in dataloader:\n",
        "        outputs = self.model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total"
      ],
      "metadata": {
        "id": "02p-nOmemN5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Model\n",
        "\n",
        "Initialise your solver with some initial config values and train the model"
      ],
      "metadata": {
        "id": "t1ve3U8SHtF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "  # Critical configs that affect the trained model\n",
        "  \"batch_size\": 512,\n",
        "  \"lr\": 0.001,\n",
        "  \"momentum\": 0.9,\n",
        "  \"num_epochs\": 50,\n",
        "  # Configs that do not influence the trained model\n",
        "  \"num_workers\": 0,\n",
        "  \"eval_batch_size\": 128,\n",
        "}\n",
        "\n",
        "input_dim = data_splits[\"X_train\"].shape[1]\n",
        "\n",
        "solver = Solver(\n",
        "    data_splits=data_splits,\n",
        "    model=MLP(\n",
        "      input_dim=input_dim,\n",
        "      hidden_dim=int(input_dim/8),\n",
        "      output_dim=10,\n",
        "    ),\n",
        "    criterion=SoftmaxCrossEntropyLoss(),\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "solver.fit(evaluate_on=\"val\")\n",
        "accuracy = solver.evaluate(evaluate_on=\"val\")\n",
        "print(f\"Final accuracy: {accuracy:.3f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lgPmLNgm2ax",
        "outputId": "829ea2d6-9195-4610-a3b2-2d484ff3c174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_dim=784, hidden_dim=98, output_dim=10\n",
            "epoch 001\ttrain_loss  0.623\tval_accuracy:  10.229%\t\n",
            "epoch 002\ttrain_loss  0.623\tval_accuracy:  10.500%\t\n",
            "epoch 003\ttrain_loss  0.623\tval_accuracy:  10.486%\t\n",
            "epoch 004\ttrain_loss  0.623\tval_accuracy:  10.986%\t\n",
            "epoch 005\ttrain_loss  0.623\tval_accuracy:  10.871%\t\n",
            "epoch 006\ttrain_loss  0.623\tval_accuracy:  12.100%\t\n",
            "epoch 007\ttrain_loss  0.623\tval_accuracy:  12.400%\t\n",
            "epoch 008\ttrain_loss  0.623\tval_accuracy:  12.471%\t\n",
            "epoch 009\ttrain_loss  0.623\tval_accuracy:  12.543%\t\n",
            "epoch 010\ttrain_loss  0.623\tval_accuracy:  12.814%\t\n",
            "epoch 011\ttrain_loss  0.623\tval_accuracy:  13.543%\t\n",
            "epoch 012\ttrain_loss  0.623\tval_accuracy:  13.457%\t\n",
            "epoch 013\ttrain_loss  0.623\tval_accuracy:  14.157%\t\n",
            "epoch 014\ttrain_loss  0.623\tval_accuracy:  14.214%\t\n",
            "epoch 015\ttrain_loss  0.623\tval_accuracy:  14.729%\t\n",
            "epoch 016\ttrain_loss  0.623\tval_accuracy:  14.914%\t\n",
            "epoch 017\ttrain_loss  0.623\tval_accuracy:  15.071%\t\n",
            "epoch 018\ttrain_loss  0.623\tval_accuracy:  14.857%\t\n",
            "epoch 019\ttrain_loss  0.623\tval_accuracy:  15.786%\t\n",
            "epoch 020\ttrain_loss  0.623\tval_accuracy:  16.300%\t\n",
            "epoch 021\ttrain_loss  0.623\tval_accuracy:  16.729%\t\n",
            "epoch 022\ttrain_loss  0.623\tval_accuracy:  17.486%\t\n",
            "epoch 023\ttrain_loss  0.623\tval_accuracy:  16.943%\t\n",
            "epoch 024\ttrain_loss  0.623\tval_accuracy:  18.057%\t\n",
            "epoch 025\ttrain_loss  0.622\tval_accuracy:  17.914%\t\n",
            "epoch 026\ttrain_loss  0.622\tval_accuracy:  18.157%\t\n",
            "epoch 027\ttrain_loss  0.622\tval_accuracy:  18.214%\t\n",
            "epoch 028\ttrain_loss  0.622\tval_accuracy:  18.629%\t\n",
            "epoch 029\ttrain_loss  0.622\tval_accuracy:  19.557%\t\n",
            "epoch 030\ttrain_loss  0.622\tval_accuracy:  19.614%\t\n",
            "epoch 031\ttrain_loss  0.622\tval_accuracy:  20.257%\t\n",
            "epoch 032\ttrain_loss  0.622\tval_accuracy:  19.900%\t\n",
            "epoch 033\ttrain_loss  0.622\tval_accuracy:  20.743%\t\n",
            "epoch 034\ttrain_loss  0.622\tval_accuracy:  20.729%\t\n",
            "epoch 035\ttrain_loss  0.622\tval_accuracy:  21.214%\t\n",
            "epoch 036\ttrain_loss  0.622\tval_accuracy:  21.357%\t\n",
            "epoch 037\ttrain_loss  0.622\tval_accuracy:  22.343%\t\n",
            "epoch 038\ttrain_loss  0.622\tval_accuracy:  22.286%\t\n",
            "epoch 039\ttrain_loss  0.622\tval_accuracy:  22.929%\t\n",
            "epoch 040\ttrain_loss  0.622\tval_accuracy:  23.200%\t\n",
            "epoch 041\ttrain_loss  0.622\tval_accuracy:  23.600%\t\n",
            "epoch 042\ttrain_loss  0.622\tval_accuracy:  23.629%\t\n",
            "epoch 043\ttrain_loss  0.622\tval_accuracy:  23.686%\t\n",
            "epoch 044\ttrain_loss  0.622\tval_accuracy:  24.743%\t\n",
            "epoch 045\ttrain_loss  0.622\tval_accuracy:  25.429%\t\n",
            "epoch 046\ttrain_loss  0.622\tval_accuracy:  25.529%\t\n",
            "epoch 047\ttrain_loss  0.622\tval_accuracy:  25.743%\t\n",
            "epoch 048\ttrain_loss  0.622\tval_accuracy:  25.757%\t\n",
            "epoch 049\ttrain_loss  0.622\tval_accuracy:  26.500%\t\n",
            "epoch 050\ttrain_loss  0.622\tval_accuracy:  27.371%\t\n",
            "Final accuracy: 26.943%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter Tuning (10 points)\n",
        "\n",
        "Now, find a config set (`batch_size`, `lr`, `momentum`) that returns a **validation-set accuracy >= 95%** at any epoch <=50 **(10 points)**.\n",
        "\n",
        "**You may not change the training data.**"
      ],
      "metadata": {
        "id": "VJwHPRhGD12W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### >>>> PUT YOUR SOLUTION HERE <<<< 10 points\n",
        "config = {\n",
        "  # Critical configs that affect the trained model\n",
        "  \"batch_size\": 32,\n",
        "  \"lr\": 0.05,\n",
        "  \"momentum\": 0.95,\n",
        "  \"num_epochs\": 50,\n",
        "  # Configs that do not influence the trained model\n",
        "  \"num_workers\": 0,\n",
        "  \"eval_batch_size\": 128,\n",
        "}\n",
        "#### >>>> ENT OF YOUR SOLUTION <<<<\n",
        "\n",
        "input_dim = data_splits[\"X_train\"].shape[1]\n",
        "\n",
        "solver = Solver(\n",
        "    data_splits=data_splits,\n",
        "    model=MLP(\n",
        "      input_dim=input_dim,\n",
        "      hidden_dim=int(input_dim/8),\n",
        "      output_dim=10,\n",
        "    ),\n",
        "    criterion=SoftmaxCrossEntropyLoss(),\n",
        "    config=config\n",
        ")\n",
        "\n",
        "solver.fit(evaluate_on=\"val\")\n",
        "accuracy = solver.evaluate(evaluate_on=\"val\")\n",
        "print(f\"Final accuracy: {accuracy:.3f}%\")"
      ],
      "metadata": {
        "id": "py-hDNi4Jcup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0154d5a-000b-48d8-b8ae-44d86fd3ee80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_dim=784, hidden_dim=98, output_dim=10\n",
            "epoch 001\ttrain_loss  0.308\tval_accuracy:  79.071%\t\n",
            "epoch 002\ttrain_loss  0.284\tval_accuracy:  87.743%\t\n",
            "epoch 003\ttrain_loss  0.279\tval_accuracy:  90.029%\t\n",
            "epoch 004\ttrain_loss  0.277\tval_accuracy:  90.414%\t\n",
            "epoch 005\ttrain_loss  0.276\tval_accuracy:  91.271%\t\n",
            "epoch 006\ttrain_loss  0.276\tval_accuracy:  91.671%\t\n",
            "epoch 007\ttrain_loss  0.275\tval_accuracy:  92.271%\t\n",
            "epoch 008\ttrain_loss  0.275\tval_accuracy:  92.757%\t\n",
            "epoch 009\ttrain_loss  0.274\tval_accuracy:  92.614%\t\n",
            "epoch 010\ttrain_loss  0.274\tval_accuracy:  92.814%\t\n",
            "epoch 011\ttrain_loss  0.274\tval_accuracy:  93.100%\t\n",
            "epoch 012\ttrain_loss  0.274\tval_accuracy:  93.314%\t\n",
            "epoch 013\ttrain_loss  0.273\tval_accuracy:  93.186%\t\n",
            "epoch 014\ttrain_loss  0.273\tval_accuracy:  93.243%\t\n",
            "epoch 015\ttrain_loss  0.273\tval_accuracy:  92.971%\t\n",
            "epoch 016\ttrain_loss  0.273\tval_accuracy:  93.886%\t\n",
            "epoch 017\ttrain_loss  0.273\tval_accuracy:  93.629%\t\n",
            "epoch 018\ttrain_loss  0.273\tval_accuracy:  93.814%\t\n",
            "epoch 019\ttrain_loss  0.272\tval_accuracy:  93.814%\t\n",
            "epoch 020\ttrain_loss  0.272\tval_accuracy:  94.000%\t\n",
            "epoch 021\ttrain_loss  0.272\tval_accuracy:  93.929%\t\n",
            "epoch 022\ttrain_loss  0.272\tval_accuracy:  94.086%\t\n",
            "epoch 023\ttrain_loss  0.272\tval_accuracy:  94.343%\t\n",
            "epoch 024\ttrain_loss  0.272\tval_accuracy:  94.386%\t\n",
            "epoch 025\ttrain_loss  0.272\tval_accuracy:  94.086%\t\n",
            "epoch 026\ttrain_loss  0.272\tval_accuracy:  94.171%\t\n",
            "epoch 027\ttrain_loss  0.272\tval_accuracy:  94.457%\t\n",
            "epoch 028\ttrain_loss  0.272\tval_accuracy:  94.657%\t\n",
            "epoch 029\ttrain_loss  0.272\tval_accuracy:  94.429%\t\n",
            "epoch 030\ttrain_loss  0.272\tval_accuracy:  94.514%\t\n",
            "epoch 031\ttrain_loss  0.272\tval_accuracy:  94.429%\t\n",
            "epoch 032\ttrain_loss  0.272\tval_accuracy:  94.471%\t\n",
            "epoch 033\ttrain_loss  0.271\tval_accuracy:  94.786%\t\n",
            "epoch 034\ttrain_loss  0.271\tval_accuracy:  94.557%\t\n",
            "epoch 035\ttrain_loss  0.271\tval_accuracy:  94.629%\t\n",
            "epoch 036\ttrain_loss  0.271\tval_accuracy:  94.757%\t\n",
            "epoch 037\ttrain_loss  0.271\tval_accuracy:  94.857%\t\n",
            "epoch 038\ttrain_loss  0.271\tval_accuracy:  95.014%\t\n",
            "epoch 039\ttrain_loss  0.271\tval_accuracy:  94.729%\t\n",
            "epoch 040\ttrain_loss  0.271\tval_accuracy:  94.929%\t\n",
            "epoch 041\ttrain_loss  0.271\tval_accuracy:  94.800%\t\n",
            "epoch 042\ttrain_loss  0.271\tval_accuracy:  94.814%\t\n",
            "epoch 043\ttrain_loss  0.271\tval_accuracy:  94.886%\t\n",
            "epoch 044\ttrain_loss  0.271\tval_accuracy:  94.800%\t\n",
            "epoch 045\ttrain_loss  0.271\tval_accuracy:  95.043%\t\n",
            "epoch 046\ttrain_loss  0.271\tval_accuracy:  95.086%\t\n",
            "epoch 047\ttrain_loss  0.271\tval_accuracy:  95.143%\t\n",
            "epoch 048\ttrain_loss  0.271\tval_accuracy:  94.757%\t\n",
            "epoch 049\ttrain_loss  0.271\tval_accuracy:  94.771%\t\n",
            "epoch 050\ttrain_loss  0.271\tval_accuracy:  95.300%\t\n",
            "Final accuracy: 95.157%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define a CNN Model\n",
        "We may take advantage of the image structure to enjoy more efficient usage of model parameters. CNNs assume that parameters can be devoted to model the composition of nearby pixels in an image, rather than any long-range dependence. We define a CNN model for you. This is a LeNet structure."
      ],
      "metadata": {
        "id": "9ok_1tvBIaEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, dropout=0.5):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
        "        self.conv2_drop = nn.Dropout2d(p=dropout)\n",
        "        self.fc1 = nn.Linear(1600, 100) # 1600 = number channels * width * height\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "        self.fc1_drop = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.reshape(-1, 1, 28, 28)\n",
        "        x = torch.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = torch.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        \n",
        "        # flatten over channel, height and width = 1600\n",
        "        x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
        "        \n",
        "        x = torch.relu(self.fc1_drop(self.fc1(x)))\n",
        "        x = torch.softmax(self.fc2(x), dim=-1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "RL0AVctW1vxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train a CNN Model"
      ],
      "metadata": {
        "id": "Oifjml3_QaG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "  # Critical configs that affect the trained model\n",
        "  \"batch_size\": 128,\n",
        "  \"lr\": 0.1,\n",
        "  \"momentum\": 0.9,\n",
        "  \"num_epochs\": 10,\n",
        "  # Configs that do not influence the trained model\n",
        "  \"num_workers\": 0,\n",
        "  \"eval_batch_size\": 128,\n",
        "}\n",
        "\n",
        "input_dim = data_splits[\"X_train\"].shape[1]\n",
        "\n",
        "solver = Solver(\n",
        "    data_splits=data_splits,\n",
        "    model=CNN(),\n",
        "    criterion=SoftmaxCrossEntropyLoss(),\n",
        "    config=config\n",
        ")\n",
        "\n",
        "solver.fit(evaluate_on=\"val\")\n",
        "accuracy = solver.evaluate(evaluate_on=\"val\")\n",
        "print(f\"Final accuracy: {accuracy:.3f}%\")"
      ],
      "metadata": {
        "id": "8FGYIfnO1xd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e6a4a1a-d689-442d-8d12-f9b65a5b9a30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 001\ttrain_loss  0.477\tval_accuracy:  58.500%\t\n",
            "epoch 002\ttrain_loss  0.435\tval_accuracy:  73.971%\t\n",
            "epoch 003\ttrain_loss  0.425\tval_accuracy:  79.786%\t\n",
            "epoch 004\ttrain_loss  0.421\tval_accuracy:  81.871%\t\n",
            "epoch 005\ttrain_loss  0.420\tval_accuracy:  82.700%\t\n",
            "epoch 006\ttrain_loss  0.419\tval_accuracy:  83.429%\t\n",
            "epoch 007\ttrain_loss  0.418\tval_accuracy:  84.286%\t\n",
            "epoch 008\ttrain_loss  0.417\tval_accuracy:  84.886%\t\n",
            "epoch 009\ttrain_loss  0.417\tval_accuracy:  85.100%\t\n",
            "epoch 010\ttrain_loss  0.417\tval_accuracy:  84.943%\t\n",
            "Final accuracy: 85.300%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Report (10 points)\n",
        "\n",
        "We want to answer the research question: Is MLP or CNN more advantageous for MNIST digit classification task?\n",
        "\n",
        "Make an argument below, based on empirical evidence, which architecture is \"better\"?\n",
        "\n",
        "For answering this question, consider the following aspects:\n",
        "- Accuracy, indeed, but also\n",
        "- Computational complexity\n",
        "  - Space and time\n",
        "  - Training and inference\n",
        "- Fairness of hyperparameter tuning and model choice\n",
        "- Error bar of accuracy\n",
        "\n",
        "Feel free to run additional model training experiments to support your argument. **(10 points)**"
      ],
      "metadata": {
        "id": "upcUH5k1L5Yc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SOLUTION:**\n",
        "\n",
        "Just based on the accuracies on the validation sets, the MLP appears to perform much better on MNIST than the CNN. However, this comparison is not really fair, because we spent a lot of time and computational capacities to find a set of hyperparameters (and even worse, a run that got above 95% accuracy on the validation set) for the MLP without spending the same amount of resources on the CNN. Unfortunately, my runtime expired and I do not want to run the experiments again, because the MLP experiment has a lot of variation and does not always reach the 95% accuracy on MNIST. For this reason, I do not run any additional tests for this task, but draw my conclusions based on the limited amount of information and outline an approach that could be used to find the better model.\n",
        "\n",
        "For a fair comparison in terms of classification quality, we would have to quantify the resources spent to find the best hyperparameters for both models and make sure they are even. Afterwards, we have to get a final evaluation on the unseen test data to really see how well the models generalize. Since the training of neural networks is stochastic, because we optimize with unbiased estimates of the true gradient, it can also make sense to repeat the training process with a fixed set of parameters several times and report the mean and standard deviation of accuracies on the test set.\n",
        "\n",
        "We randomly select train, validation and test sets on our own, so far with the train-test-split method. This gives us a lot of flexibility and if we want to find out which model classes between MLPs and CNNs perform better in general, we can perform cross-validation with a fixed test set or maybe even nested cross validation to have several independent test sets. This way we would have a much higher chance of actually finding the better of the two approaches.\n",
        "\n",
        "So far, we only discussed the quality based on accuracy. However, there are other hard or soft metrics than can be used to define how good a model performs, eg. number of parameters, how robust it is for hyperparameter choices, FLOPs needed for training, time needed for training (does not have to be identical), inference time, and many others.\n",
        "\n",
        "Usually, CNN variations are known to perform much better on image data than MLPs, if you spend the same amount of computational resources. The reason is that MLPs use dense layers that cause large amounts of parameters and FLOPs, because they grow quadratically with the number of neurons per layer. CNNs, on the other hand, exploit the spatial locality of most images and are efficient thanks to weight-sharing in convolutional kernels. In our case, this appears no to be true and the CNN trains much slower than the MLP. The reasons are that the input data has a very low input resolution of only 28x28=784 pixels and the MLP is defined in such a way that it is much more efficient than the CNN on these input. It uses a fairly small hiden layer with only 98 neurons, while the CNN has 64 filters in the last convolutional layer that is connected to a fully-connected layer without any global pooling. \n",
        "\n",
        "Evaluating based on all of the aforementioned KPIs is very difficult. For this reason it usually makes sense to pick one of them, eg. the number of FLOPs needed for training, define several differing MLPs and CNNs based on this metric and then train and evaluate them. In case of MLPs and CNNs we could increase the number of layers and neurons, respectively feature maps, per layer. If enough data is available and the regularization is chosen according to the model capacity, the more complex models should perform better, resulting in an accuracy curve for both of the model classes. In a best case scenario even with error bars for both of them. This allows us to pick the pareto-optimal model for a chosen computational budget. \n",
        "\n",
        "I also generated an \"ENT OF YOUR SOLUTION\" for this submission, because I think that typo was very funny:"
      ],
      "metadata": {
        "id": "OLhHQmChOIrL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![ENT](https://drive.google.com/uc?export=view&id=1RuuCLvKkWXJT2HSEThUzVSw1JG7oZLni) "
      ],
      "metadata": {
        "id": "ayUHAdatrG_a"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "49qReNrRruzK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}